Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################


This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [176.0, 176.0, 176.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['CTNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset500_HeadNeckPTCT', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [176, 176, 176], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3084.078125, 'mean': 37.496119355221374, 'median': 41.667911529541016, 'min': -1075.762939453125, 'percentile_00_5': -132.0876007080078, 'percentile_99_5': 155.04347229003906, 'std': 44.774756195436765}, '1': {'max': 44.05201721191406, 'mean': 6.44351180606988, 'median': 5.461172103881836, 'min': -0.37562260031700134, 'percentile_00_5': 0.867931604385376, 'percentile_99_5': 23.637962341308594, 'std': 4.242073649695497}}} 

2024-04-22 12:41:17.184492: unpacking dataset...
2024-04-22 12:41:19.771744: unpacking done...
2024-04-22 12:41:19.772313: do_dummy_2d_data_aug: False
2024-04-22 12:41:19.774195: Using splits from existing split file: /media/HDD_4TB_2/sergio/TFM/hecktor/hecktor/data/nnUNet_preprocessed/Dataset500_HeadNeckPTCT/splits_final.json
2024-04-22 12:41:19.774474: The split file contains 5 splits.
2024-04-22 12:41:19.774503: Desired fold for training: 4
2024-04-22 12:41:19.774523: This split has 377 training and 94 validation cases.
2024-04-22 12:41:19.780154: Unable to plot network architecture:
2024-04-22 12:41:19.780209: No module named 'IPython'
2024-04-22 12:41:19.783610: 
2024-04-22 12:41:19.783652: Epoch 0
2024-04-22 12:41:19.783708: Current learning rate: 0.01
using pin_memory on device 0
using pin_memory on device 0
2024-04-22 12:42:55.601967: train_loss -0.174
2024-04-22 12:42:55.602161: val_loss -0.3494
2024-04-22 12:42:55.602217: Pseudo dice [0.5882, 0.4077]
2024-04-22 12:42:55.602274: Epoch time: 95.82 s
2024-04-22 12:42:55.602313: Yayy! New best EMA pseudo Dice: 0.498
2024-04-22 12:42:59.661907: 
2024-04-22 12:42:59.662032: Epoch 1
2024-04-22 12:42:59.662115: Current learning rate: 0.00991
2024-04-22 12:44:41.621346: train_loss -0.4422
2024-04-22 12:44:41.621584: val_loss -0.4381
2024-04-22 12:44:41.621633: Pseudo dice [0.6939, 0.5888]
2024-04-22 12:44:41.621689: Epoch time: 101.96 s
2024-04-22 12:44:41.621726: Yayy! New best EMA pseudo Dice: 0.5123
2024-04-22 12:44:44.938651: 
2024-04-22 12:44:44.938759: Epoch 2
2024-04-22 12:44:44.938841: Current learning rate: 0.00982
2024-04-22 12:46:30.940143: train_loss -0.4827
2024-04-22 12:46:30.940362: val_loss -0.5047
2024-04-22 12:46:30.940408: Pseudo dice [0.7818, 0.6246]
2024-04-22 12:46:30.940458: Epoch time: 106.0 s
2024-04-22 12:46:30.940495: Yayy! New best EMA pseudo Dice: 0.5314
2024-04-22 12:46:34.588921: 
2024-04-22 12:46:34.589040: Epoch 3
2024-04-22 12:46:34.589124: Current learning rate: 0.00973
2024-04-22 12:48:21.261452: train_loss -0.5005
2024-04-22 12:48:21.261655: val_loss -0.4839
2024-04-22 12:48:21.261700: Pseudo dice [0.7554, 0.6267]
2024-04-22 12:48:21.261748: Epoch time: 106.67 s
2024-04-22 12:48:21.261782: Yayy! New best EMA pseudo Dice: 0.5474
2024-04-22 12:48:24.858878: 
2024-04-22 12:48:24.859001: Epoch 4
2024-04-22 12:48:24.859086: Current learning rate: 0.00964
2024-04-22 12:50:12.751640: train_loss -0.4872
2024-04-22 12:50:12.751914: val_loss -0.4714
2024-04-22 12:50:12.751992: Pseudo dice [0.7453, 0.5117]
2024-04-22 12:50:12.752081: Epoch time: 107.89 s
2024-04-22 12:50:12.752151: Yayy! New best EMA pseudo Dice: 0.5555
2024-04-22 12:50:16.652468: 
2024-04-22 12:50:16.652564: Epoch 5
2024-04-22 12:50:16.652653: Current learning rate: 0.00955
2024-04-22 12:52:04.737223: train_loss -0.4937
2024-04-22 12:52:04.737397: val_loss -0.5264
2024-04-22 12:52:04.737441: Pseudo dice [0.7528, 0.6539]
2024-04-22 12:52:04.737487: Epoch time: 108.09 s
2024-04-22 12:52:04.737522: Yayy! New best EMA pseudo Dice: 0.5703
2024-04-22 12:52:08.110258: 
2024-04-22 12:52:08.110376: Epoch 6
2024-04-22 12:52:08.110457: Current learning rate: 0.00946
2024-04-22 12:53:57.235766: train_loss -0.5224
2024-04-22 12:53:57.235899: val_loss -0.545
2024-04-22 12:53:57.235941: Pseudo dice [0.742, 0.5903]
2024-04-22 12:53:57.235988: Epoch time: 109.13 s
2024-04-22 12:53:57.236022: Yayy! New best EMA pseudo Dice: 0.5799
2024-04-22 12:54:00.424896: 
2024-04-22 12:54:00.424998: Epoch 7
2024-04-22 12:54:00.425082: Current learning rate: 0.00937
2024-04-22 12:55:49.731796: train_loss -0.5338
2024-04-22 12:55:49.731938: val_loss -0.5191
2024-04-22 12:55:49.731982: Pseudo dice [0.753, 0.6121]
2024-04-22 12:55:49.732029: Epoch time: 109.31 s
2024-04-22 12:55:49.732063: Yayy! New best EMA pseudo Dice: 0.5901
2024-04-22 12:55:54.005209: 
2024-04-22 12:55:54.005308: Epoch 8
2024-04-22 12:55:54.005388: Current learning rate: 0.00928
2024-04-22 12:57:43.430119: train_loss -0.5036
2024-04-22 12:57:43.430278: val_loss -0.545
2024-04-22 12:57:43.430322: Pseudo dice [0.7589, 0.6609]
2024-04-22 12:57:43.430381: Epoch time: 109.43 s
2024-04-22 12:57:43.430416: Yayy! New best EMA pseudo Dice: 0.6021
2024-04-22 12:57:47.429416: 
2024-04-22 12:57:47.429520: Epoch 9
2024-04-22 12:57:47.429603: Current learning rate: 0.00919
2024-04-22 12:59:37.325686: train_loss -0.5282
2024-04-22 12:59:37.325860: val_loss -0.5364
2024-04-22 12:59:37.325911: Pseudo dice [0.7771, 0.6065]
2024-04-22 12:59:37.325962: Epoch time: 109.9 s
2024-04-22 12:59:37.326000: Yayy! New best EMA pseudo Dice: 0.6111
2024-04-22 12:59:40.407850: 
2024-04-22 12:59:40.407961: Epoch 10
2024-04-22 12:59:40.408041: Current learning rate: 0.0091
2024-04-22 13:01:31.206042: train_loss -0.5248
2024-04-22 13:01:31.206238: val_loss -0.5402
2024-04-22 13:01:31.206284: Pseudo dice [0.7616, 0.645]
2024-04-22 13:01:31.206344: Epoch time: 110.8 s
2024-04-22 13:01:31.206388: Yayy! New best EMA pseudo Dice: 0.6203
2024-04-22 13:01:34.474873: 
2024-04-22 13:01:34.475049: Epoch 11
2024-04-22 13:01:34.475145: Current learning rate: 0.009
2024-04-22 13:03:25.212424: train_loss -0.5297
2024-04-22 13:03:25.212588: val_loss -0.5385
2024-04-22 13:03:25.212631: Pseudo dice [0.7995, 0.6165]
2024-04-22 13:03:25.212679: Epoch time: 110.74 s
2024-04-22 13:03:25.212712: Yayy! New best EMA pseudo Dice: 0.6291
2024-04-22 13:03:28.048537: 
2024-04-22 13:03:28.048649: Epoch 12
2024-04-22 13:03:28.048731: Current learning rate: 0.00891
2024-04-22 13:05:19.077956: train_loss -0.5298
2024-04-22 13:05:19.078138: val_loss -0.5109
2024-04-22 13:05:19.078182: Pseudo dice [0.7616, 0.6045]
2024-04-22 13:05:19.078235: Epoch time: 111.03 s
2024-04-22 13:05:19.078269: Yayy! New best EMA pseudo Dice: 0.6345
2024-04-22 13:05:21.864401: 
2024-04-22 13:05:21.864512: Epoch 13
2024-04-22 13:05:21.864599: Current learning rate: 0.00882
2024-04-22 13:07:12.973311: train_loss -0.5525
2024-04-22 13:07:12.973490: val_loss -0.5361
2024-04-22 13:07:12.973536: Pseudo dice [0.7665, 0.6509]
2024-04-22 13:07:12.973586: Epoch time: 111.11 s
2024-04-22 13:07:12.973620: Yayy! New best EMA pseudo Dice: 0.6419
2024-04-22 13:07:17.004205: 
2024-04-22 13:07:17.004317: Epoch 14
2024-04-22 13:07:17.004398: Current learning rate: 0.00873
2024-04-22 13:09:07.548345: train_loss -0.5418
2024-04-22 13:09:07.548499: val_loss -0.5497
2024-04-22 13:09:07.548542: Pseudo dice [0.762, 0.656]
2024-04-22 13:09:07.548590: Epoch time: 110.54 s
2024-04-22 13:09:07.548624: Yayy! New best EMA pseudo Dice: 0.6486
2024-04-22 13:09:10.827306: 
2024-04-22 13:09:10.827420: Epoch 15
2024-04-22 13:09:10.827504: Current learning rate: 0.00864
2024-04-22 13:11:02.014782: train_loss -0.5539
2024-04-22 13:11:02.014981: val_loss -0.5524
2024-04-22 13:11:02.015025: Pseudo dice [0.7829, 0.644]
2024-04-22 13:11:02.015075: Epoch time: 111.19 s
2024-04-22 13:11:02.015111: Yayy! New best EMA pseudo Dice: 0.6551
2024-04-22 13:11:05.481229: 
2024-04-22 13:11:05.481349: Epoch 16
2024-04-22 13:11:05.481431: Current learning rate: 0.00855
2024-04-22 13:12:56.395094: train_loss -0.5364
2024-04-22 13:12:56.395260: val_loss -0.5344
2024-04-22 13:12:56.395303: Pseudo dice [0.7921, 0.6108]
2024-04-22 13:12:56.395350: Epoch time: 110.91 s
2024-04-22 13:12:56.395383: Yayy! New best EMA pseudo Dice: 0.6597
2024-04-22 13:12:59.780513: 
2024-04-22 13:12:59.780631: Epoch 17
2024-04-22 13:12:59.780714: Current learning rate: 0.00846
2024-04-22 13:14:50.924118: train_loss -0.5532
2024-04-22 13:14:50.924259: val_loss -0.5753
2024-04-22 13:14:50.924302: Pseudo dice [0.755, 0.6539]
2024-04-22 13:14:50.924349: Epoch time: 111.14 s
2024-04-22 13:14:50.924382: Yayy! New best EMA pseudo Dice: 0.6642
2024-04-22 13:14:54.325898: 
2024-04-22 13:14:54.326023: Epoch 18
2024-04-22 13:14:54.326111: Current learning rate: 0.00836
2024-04-22 13:16:45.461852: train_loss -0.5456
2024-04-22 13:16:45.462006: val_loss -0.5339
2024-04-22 13:16:45.462049: Pseudo dice [0.7967, 0.5793]
2024-04-22 13:16:45.462100: Epoch time: 111.14 s
2024-04-22 13:16:45.462132: Yayy! New best EMA pseudo Dice: 0.6666
2024-04-22 13:16:48.814023: 
2024-04-22 13:16:48.814133: Epoch 19
2024-04-22 13:16:48.814215: Current learning rate: 0.00827
2024-04-22 13:18:40.105121: train_loss -0.5473
2024-04-22 13:18:40.105267: val_loss -0.5525
2024-04-22 13:18:40.105309: Pseudo dice [0.7973, 0.6411]
2024-04-22 13:18:40.105355: Epoch time: 111.29 s
2024-04-22 13:18:40.105389: Yayy! New best EMA pseudo Dice: 0.6718
2024-04-22 13:18:44.012080: 
2024-04-22 13:18:44.012194: Epoch 20
2024-04-22 13:18:44.012275: Current learning rate: 0.00818
2024-04-22 13:20:35.321861: train_loss -0.5637
2024-04-22 13:20:35.322012: val_loss -0.5858
2024-04-22 13:20:35.322054: Pseudo dice [0.8165, 0.6636]
2024-04-22 13:20:35.322101: Epoch time: 111.31 s
2024-04-22 13:20:35.322135: Yayy! New best EMA pseudo Dice: 0.6787
2024-04-22 13:20:38.838454: 
2024-04-22 13:20:38.838570: Epoch 21
2024-04-22 13:20:38.838650: Current learning rate: 0.00809
2024-04-22 13:22:30.152836: train_loss -0.5602
2024-04-22 13:22:30.153037: val_loss -0.5673
2024-04-22 13:22:30.153086: Pseudo dice [0.7596, 0.6523]
2024-04-22 13:22:30.153148: Epoch time: 111.32 s
2024-04-22 13:22:30.153185: Yayy! New best EMA pseudo Dice: 0.6814
2024-04-22 13:22:33.415129: 
2024-04-22 13:22:33.415248: Epoch 22
2024-04-22 13:22:33.415334: Current learning rate: 0.008
2024-04-22 13:24:25.260866: train_loss -0.5614
2024-04-22 13:24:25.261014: val_loss -0.5808
2024-04-22 13:24:25.261091: Pseudo dice [0.8035, 0.6724]
2024-04-22 13:24:25.261153: Epoch time: 111.85 s
2024-04-22 13:24:25.261212: Yayy! New best EMA pseudo Dice: 0.687
2024-04-22 13:24:28.240517: 
2024-04-22 13:24:28.240629: Epoch 23
2024-04-22 13:24:28.240711: Current learning rate: 0.0079
2024-04-22 13:26:20.164917: train_loss -0.5657
2024-04-22 13:26:20.165087: val_loss -0.6085
2024-04-22 13:26:20.165131: Pseudo dice [0.8008, 0.643]
2024-04-22 13:26:20.165179: Epoch time: 111.93 s
2024-04-22 13:26:20.165213: Yayy! New best EMA pseudo Dice: 0.6905
2024-04-22 13:26:24.446851: 
2024-04-22 13:26:24.446973: Epoch 24
2024-04-22 13:26:24.447064: Current learning rate: 0.00781
2024-04-22 13:28:15.506751: train_loss -0.5754
2024-04-22 13:28:15.506884: val_loss -0.5634
2024-04-22 13:28:15.506928: Pseudo dice [0.8058, 0.6155]
2024-04-22 13:28:15.506978: Epoch time: 111.06 s
2024-04-22 13:28:15.507015: Yayy! New best EMA pseudo Dice: 0.6925
2024-04-22 13:28:19.311466: 
2024-04-22 13:28:19.311562: Epoch 25
2024-04-22 13:28:19.311644: Current learning rate: 0.00772
2024-04-22 13:30:10.798085: train_loss -0.5754
2024-04-22 13:30:10.798223: val_loss -0.5618
2024-04-22 13:30:10.798265: Pseudo dice [0.7868, 0.6873]
2024-04-22 13:30:10.798312: Epoch time: 111.49 s
2024-04-22 13:30:10.798358: Yayy! New best EMA pseudo Dice: 0.697
2024-04-22 13:30:14.325140: 
2024-04-22 13:30:14.325237: Epoch 26
2024-04-22 13:30:14.325324: Current learning rate: 0.00763
2024-04-22 13:32:06.013128: train_loss -0.5495
2024-04-22 13:32:06.013286: val_loss -0.5633
2024-04-22 13:32:06.013329: Pseudo dice [0.8075, 0.6247]
2024-04-22 13:32:06.013375: Epoch time: 111.69 s
2024-04-22 13:32:06.013411: Yayy! New best EMA pseudo Dice: 0.6989
2024-04-22 13:32:08.893162: 
2024-04-22 13:32:08.893275: Epoch 27
2024-04-22 13:32:08.893360: Current learning rate: 0.00753
2024-04-22 13:34:01.269994: train_loss -0.5965
2024-04-22 13:34:01.270168: val_loss -0.5661
2024-04-22 13:34:01.270212: Pseudo dice [0.7976, 0.6675]
2024-04-22 13:34:01.270259: Epoch time: 112.38 s
2024-04-22 13:34:01.270293: Yayy! New best EMA pseudo Dice: 0.7023
2024-04-22 13:34:04.155411: 
2024-04-22 13:34:04.155501: Epoch 28
2024-04-22 13:34:04.155581: Current learning rate: 0.00744
2024-04-22 13:35:56.401026: train_loss -0.5857
2024-04-22 13:35:56.401255: val_loss -0.5732
2024-04-22 13:35:56.401302: Pseudo dice [0.8004, 0.6538]
2024-04-22 13:35:56.401353: Epoch time: 112.25 s
2024-04-22 13:35:56.401389: Yayy! New best EMA pseudo Dice: 0.7047
2024-04-22 13:35:59.611444: 
2024-04-22 13:35:59.611682: Epoch 29
2024-04-22 13:35:59.611799: Current learning rate: 0.00735
2024-04-22 13:37:51.577550: train_loss -0.5655
2024-04-22 13:37:51.577715: val_loss -0.573
2024-04-22 13:37:51.577758: Pseudo dice [0.8014, 0.6569]
2024-04-22 13:37:51.577807: Epoch time: 111.97 s
2024-04-22 13:37:51.577840: Yayy! New best EMA pseudo Dice: 0.7072
2024-04-22 13:37:55.010704: 
2024-04-22 13:37:55.010811: Epoch 30
2024-04-22 13:37:55.010894: Current learning rate: 0.00725
2024-04-22 13:39:46.752967: train_loss -0.5938
2024-04-22 13:39:46.753120: val_loss -0.6173
2024-04-22 13:39:46.753163: Pseudo dice [0.8306, 0.7171]
2024-04-22 13:39:46.753210: Epoch time: 111.74 s
2024-04-22 13:39:46.753244: Yayy! New best EMA pseudo Dice: 0.7139
2024-04-22 13:39:50.072963: 
2024-04-22 13:39:50.073070: Epoch 31
2024-04-22 13:39:50.073149: Current learning rate: 0.00716
2024-04-22 13:41:42.042654: train_loss -0.5739
2024-04-22 13:41:42.042823: val_loss -0.6013
2024-04-22 13:41:42.042866: Pseudo dice [0.7856, 0.6608]
2024-04-22 13:41:42.042913: Epoch time: 111.97 s
2024-04-22 13:41:42.042949: Yayy! New best EMA pseudo Dice: 0.7148
2024-04-22 13:41:45.799803: 
2024-04-22 13:41:45.799910: Epoch 32
2024-04-22 13:41:45.799990: Current learning rate: 0.00707
2024-04-22 13:43:37.386969: train_loss -0.5872
2024-04-22 13:43:37.387135: val_loss -0.5752
2024-04-22 13:43:37.387182: Pseudo dice [0.8188, 0.6759]
2024-04-22 13:43:37.387230: Epoch time: 111.59 s
2024-04-22 13:43:37.387264: Yayy! New best EMA pseudo Dice: 0.718
2024-04-22 13:43:40.875236: 
2024-04-22 13:43:40.875358: Epoch 33
2024-04-22 13:43:40.875444: Current learning rate: 0.00697
2024-04-22 13:45:32.804717: train_loss -0.5582
2024-04-22 13:45:32.804908: val_loss -0.5654
2024-04-22 13:45:32.804952: Pseudo dice [0.7722, 0.6618]
2024-04-22 13:45:32.804999: Epoch time: 111.93 s
2024-04-22 13:45:33.675082: 
2024-04-22 13:45:33.675193: Epoch 34
2024-04-22 13:45:33.675273: Current learning rate: 0.00688
2024-04-22 13:47:26.774431: train_loss -0.5886
2024-04-22 13:47:26.774587: val_loss -0.5963
2024-04-22 13:47:26.774629: Pseudo dice [0.8004, 0.7085]
2024-04-22 13:47:26.774676: Epoch time: 113.1 s
2024-04-22 13:47:26.774710: Yayy! New best EMA pseudo Dice: 0.7216
2024-04-22 13:47:29.627655: 
2024-04-22 13:47:29.627763: Epoch 35
2024-04-22 13:47:29.627844: Current learning rate: 0.00679
2024-04-22 13:49:21.692923: train_loss -0.5722
2024-04-22 13:49:21.693111: val_loss -0.5849
2024-04-22 13:49:21.693157: Pseudo dice [0.821, 0.6849]
2024-04-22 13:49:21.693206: Epoch time: 112.07 s
2024-04-22 13:49:21.693239: Yayy! New best EMA pseudo Dice: 0.7247
2024-04-22 13:49:25.586394: 
2024-04-22 13:49:25.586514: Epoch 36
2024-04-22 13:49:25.586598: Current learning rate: 0.00669
2024-04-22 13:51:17.273963: train_loss -0.5775
2024-04-22 13:51:17.274101: val_loss -0.5691
2024-04-22 13:51:17.274143: Pseudo dice [0.7983, 0.6688]
2024-04-22 13:51:17.274189: Epoch time: 111.69 s
2024-04-22 13:51:17.274223: Yayy! New best EMA pseudo Dice: 0.7256
2024-04-22 13:51:20.334516: 
2024-04-22 13:51:20.334624: Epoch 37
2024-04-22 13:51:20.334702: Current learning rate: 0.0066
2024-04-22 13:53:12.875394: train_loss -0.5801
2024-04-22 13:53:12.875560: val_loss -0.566
2024-04-22 13:53:12.875601: Pseudo dice [0.8059, 0.6944]
2024-04-22 13:53:12.875648: Epoch time: 112.54 s
2024-04-22 13:53:12.875682: Yayy! New best EMA pseudo Dice: 0.7281
2024-04-22 13:53:17.203390: 
2024-04-22 13:53:17.203498: Epoch 38
2024-04-22 13:53:17.203583: Current learning rate: 0.0065
2024-04-22 13:55:08.722353: train_loss -0.591
2024-04-22 13:55:08.722518: val_loss -0.5962
2024-04-22 13:55:08.722563: Pseudo dice [0.8039, 0.7098]
2024-04-22 13:55:08.722611: Epoch time: 111.52 s
2024-04-22 13:55:08.722645: Yayy! New best EMA pseudo Dice: 0.7309
2024-04-22 13:55:12.344473: 
2024-04-22 13:55:12.344597: Epoch 39
2024-04-22 13:55:12.344688: Current learning rate: 0.00641
2024-04-22 13:57:04.572532: train_loss -0.5807
2024-04-22 13:57:04.572687: val_loss -0.6062
2024-04-22 13:57:04.572730: Pseudo dice [0.8294, 0.6946]
2024-04-22 13:57:04.572775: Epoch time: 112.23 s
2024-04-22 13:57:04.572807: Yayy! New best EMA pseudo Dice: 0.734
2024-04-22 13:57:07.666307: 
2024-04-22 13:57:07.666439: Epoch 40
2024-04-22 13:57:07.666524: Current learning rate: 0.00631
2024-04-22 13:58:59.892597: train_loss -0.589
2024-04-22 13:58:59.892789: val_loss -0.6027
2024-04-22 13:58:59.892833: Pseudo dice [0.8134, 0.6902]
2024-04-22 13:58:59.892884: Epoch time: 112.23 s
2024-04-22 13:58:59.892919: Yayy! New best EMA pseudo Dice: 0.7358
2024-04-22 13:59:03.192058: 
2024-04-22 13:59:03.192167: Epoch 41
2024-04-22 13:59:03.192245: Current learning rate: 0.00622
2024-04-22 14:00:55.293074: train_loss -0.5723
2024-04-22 14:00:55.293227: val_loss -0.5854
2024-04-22 14:00:55.293270: Pseudo dice [0.7693, 0.7062]
2024-04-22 14:00:55.293317: Epoch time: 112.1 s
2024-04-22 14:00:55.293351: Yayy! New best EMA pseudo Dice: 0.736
2024-04-22 14:00:58.493599: 
2024-04-22 14:00:58.493710: Epoch 42
2024-04-22 14:00:58.493788: Current learning rate: 0.00612
2024-04-22 14:02:50.570453: train_loss -0.5845
2024-04-22 14:02:50.570668: val_loss -0.5708
2024-04-22 14:02:50.570793: Pseudo dice [0.7873, 0.6597]
2024-04-22 14:02:50.570864: Epoch time: 112.08 s
2024-04-22 14:02:51.409431: 
2024-04-22 14:02:51.409549: Epoch 43
2024-04-22 14:02:51.409633: Current learning rate: 0.00603
2024-04-22 14:04:44.854323: train_loss -0.5794
2024-04-22 14:04:44.854484: val_loss -0.6217
2024-04-22 14:04:44.854527: Pseudo dice [0.8213, 0.7108]
2024-04-22 14:04:44.854573: Epoch time: 113.45 s
2024-04-22 14:04:44.854608: Yayy! New best EMA pseudo Dice: 0.7379
2024-04-22 14:04:48.869135: 
2024-04-22 14:04:48.869245: Epoch 44
2024-04-22 14:04:48.869325: Current learning rate: 0.00593
2024-04-22 14:06:40.472398: train_loss -0.5982
2024-04-22 14:06:40.472589: val_loss -0.5836
2024-04-22 14:06:40.472634: Pseudo dice [0.8083, 0.6634]
2024-04-22 14:06:40.472686: Epoch time: 111.6 s
2024-04-22 14:06:41.518033: 
2024-04-22 14:06:41.518174: Epoch 45
2024-04-22 14:06:41.518257: Current learning rate: 0.00584
2024-04-22 14:08:34.711289: train_loss -0.5906
2024-04-22 14:08:34.711442: val_loss -0.5834
2024-04-22 14:08:34.711484: Pseudo dice [0.8126, 0.691]
2024-04-22 14:08:34.711533: Epoch time: 113.19 s
2024-04-22 14:08:34.711566: Yayy! New best EMA pseudo Dice: 0.7391
2024-04-22 14:08:38.532598: 
2024-04-22 14:08:38.532712: Epoch 46
2024-04-22 14:08:38.532795: Current learning rate: 0.00574
2024-04-22 14:10:30.325978: train_loss -0.594
2024-04-22 14:10:30.326128: val_loss -0.5534
2024-04-22 14:10:30.326171: Pseudo dice [0.7995, 0.6715]
2024-04-22 14:10:30.326217: Epoch time: 111.79 s
2024-04-22 14:10:31.152203: 
2024-04-22 14:10:31.152315: Epoch 47
2024-04-22 14:10:31.152393: Current learning rate: 0.00565
2024-04-22 14:12:24.583900: train_loss -0.6224
2024-04-22 14:12:24.584073: val_loss -0.5824
2024-04-22 14:12:24.584116: Pseudo dice [0.8011, 0.7133]
2024-04-22 14:12:24.584165: Epoch time: 113.43 s
2024-04-22 14:12:24.584204: Yayy! New best EMA pseudo Dice: 0.7406
2024-04-22 14:12:28.507581: 
2024-04-22 14:12:28.507684: Epoch 48
2024-04-22 14:12:28.507765: Current learning rate: 0.00555
2024-04-22 14:14:20.208234: train_loss -0.5876
2024-04-22 14:14:20.208459: val_loss -0.598
2024-04-22 14:14:20.208505: Pseudo dice [0.8181, 0.6573]
2024-04-22 14:14:20.208556: Epoch time: 111.7 s
2024-04-22 14:14:21.068184: 
2024-04-22 14:14:21.068295: Epoch 49
2024-04-22 14:14:21.068381: Current learning rate: 0.00546
2024-04-22 14:16:14.175855: train_loss -0.6165
2024-04-22 14:16:14.176013: val_loss -0.5663
2024-04-22 14:16:14.176057: Pseudo dice [0.8142, 0.6394]
2024-04-22 14:16:14.176104: Epoch time: 113.11 s
2024-04-22 14:16:18.424708: 
2024-04-22 14:16:18.424819: Epoch 50
2024-04-22 14:16:18.424899: Current learning rate: 0.00536
2024-04-22 14:18:09.976929: train_loss -0.5975
2024-04-22 14:18:09.977149: val_loss -0.6041
2024-04-22 14:18:09.977193: Pseudo dice [0.8011, 0.6629]
2024-04-22 14:18:09.977250: Epoch time: 111.55 s
2024-04-22 14:18:11.006263: 
2024-04-22 14:18:11.006387: Epoch 51
2024-04-22 14:18:11.006470: Current learning rate: 0.00526
2024-04-22 14:20:03.987504: train_loss -0.5818
2024-04-22 14:20:03.987677: val_loss -0.602
2024-04-22 14:20:03.987720: Pseudo dice [0.8162, 0.6858]
2024-04-22 14:20:03.987769: Epoch time: 112.98 s
2024-04-22 14:20:04.833568: 
2024-04-22 14:20:04.833687: Epoch 52
2024-04-22 14:20:04.833770: Current learning rate: 0.00517
2024-04-22 14:21:57.978189: train_loss -0.6044
2024-04-22 14:21:57.978314: val_loss -0.6254
2024-04-22 14:21:57.978414: Pseudo dice [0.7885, 0.7027]
2024-04-22 14:21:57.978482: Epoch time: 113.15 s
2024-04-22 14:21:58.827991: 
2024-04-22 14:21:58.828104: Epoch 53
2024-04-22 14:21:58.828185: Current learning rate: 0.00507
2024-04-22 14:23:52.120224: train_loss -0.6013
2024-04-22 14:23:52.120379: val_loss -0.5914
2024-04-22 14:23:52.120422: Pseudo dice [0.7846, 0.6917]
2024-04-22 14:23:52.120469: Epoch time: 113.29 s
2024-04-22 14:23:52.967128: 
2024-04-22 14:23:52.967235: Epoch 54
2024-04-22 14:23:52.967315: Current learning rate: 0.00497
2024-04-22 14:25:46.463334: train_loss -0.5989
2024-04-22 14:25:46.463485: val_loss -0.6091
2024-04-22 14:25:46.463528: Pseudo dice [0.8181, 0.7371]
2024-04-22 14:25:46.463576: Epoch time: 113.5 s
2024-04-22 14:25:46.463610: Yayy! New best EMA pseudo Dice: 0.7437
2024-04-22 14:25:49.736163: 
2024-04-22 14:25:49.736274: Epoch 55
2024-04-22 14:25:49.736359: Current learning rate: 0.00487
2024-04-22 14:27:42.095593: train_loss -0.6085
2024-04-22 14:27:42.095758: val_loss -0.5846
2024-04-22 14:27:42.095802: Pseudo dice [0.7918, 0.6597]
2024-04-22 14:27:42.095853: Epoch time: 112.36 s
2024-04-22 14:27:42.944593: 
2024-04-22 14:27:42.944704: Epoch 56
2024-04-22 14:27:42.944784: Current learning rate: 0.00478
2024-04-22 14:29:36.422266: train_loss -0.6096
2024-04-22 14:29:36.422428: val_loss -0.5957
2024-04-22 14:29:36.422472: Pseudo dice [0.817, 0.6637]
2024-04-22 14:29:36.422518: Epoch time: 113.48 s
2024-04-22 14:29:37.451868: 
2024-04-22 14:29:37.451968: Epoch 57
2024-04-22 14:29:37.452053: Current learning rate: 0.00468
2024-04-22 14:31:30.895510: train_loss -0.6136
2024-04-22 14:31:30.895707: val_loss -0.5638
2024-04-22 14:31:30.895757: Pseudo dice [0.8253, 0.6726]
2024-04-22 14:31:30.895809: Epoch time: 113.44 s
2024-04-22 14:31:31.765246: 
2024-04-22 14:31:31.765361: Epoch 58
2024-04-22 14:31:31.765444: Current learning rate: 0.00458
2024-04-22 14:33:24.934650: train_loss -0.623
2024-04-22 14:33:24.934802: val_loss -0.5916
2024-04-22 14:33:24.934844: Pseudo dice [0.8042, 0.7143]
2024-04-22 14:33:24.934890: Epoch time: 113.17 s
2024-04-22 14:33:24.934922: Yayy! New best EMA pseudo Dice: 0.7442
2024-04-22 14:33:27.618309: 
2024-04-22 14:33:27.618432: Epoch 59
2024-04-22 14:33:27.618518: Current learning rate: 0.00448
2024-04-22 14:35:19.750751: train_loss -0.624
2024-04-22 14:35:19.750966: val_loss -0.5705
2024-04-22 14:35:19.751013: Pseudo dice [0.7973, 0.6884]
2024-04-22 14:35:19.751061: Epoch time: 112.13 s
2024-04-22 14:35:20.610685: 
2024-04-22 14:35:20.610793: Epoch 60
2024-04-22 14:35:20.610878: Current learning rate: 0.00438
2024-04-22 14:37:14.068713: train_loss -0.6148
2024-04-22 14:37:14.068868: val_loss -0.591
2024-04-22 14:37:14.068911: Pseudo dice [0.8061, 0.6774]
2024-04-22 14:37:14.068957: Epoch time: 113.46 s
2024-04-22 14:37:14.928985: 
2024-04-22 14:37:14.929075: Epoch 61
2024-04-22 14:37:14.929156: Current learning rate: 0.00429
2024-04-22 14:39:08.024914: train_loss -0.6126
2024-04-22 14:39:08.025101: val_loss -0.6104
2024-04-22 14:39:08.025143: Pseudo dice [0.8198, 0.7079]
2024-04-22 14:39:08.025192: Epoch time: 113.1 s
2024-04-22 14:39:08.025226: Yayy! New best EMA pseudo Dice: 0.7458
2024-04-22 14:39:11.976089: 
2024-04-22 14:39:11.976200: Epoch 62
2024-04-22 14:39:11.976275: Current learning rate: 0.00419
2024-04-22 14:41:04.020614: train_loss -0.6068
2024-04-22 14:41:04.020767: val_loss -0.5757
2024-04-22 14:41:04.020810: Pseudo dice [0.8129, 0.7233]
2024-04-22 14:41:04.020856: Epoch time: 112.05 s
2024-04-22 14:41:04.020891: Yayy! New best EMA pseudo Dice: 0.748
2024-04-22 14:41:07.264446: 
2024-04-22 14:41:07.264564: Epoch 63
2024-04-22 14:41:07.264644: Current learning rate: 0.00409
2024-04-22 14:42:59.481308: train_loss -0.6197
2024-04-22 14:42:59.481464: val_loss -0.5523
2024-04-22 14:42:59.481513: Pseudo dice [0.8095, 0.6961]
2024-04-22 14:42:59.481560: Epoch time: 112.22 s
2024-04-22 14:42:59.481594: Yayy! New best EMA pseudo Dice: 0.7485
2024-04-22 14:43:02.962826: 
2024-04-22 14:43:02.962945: Epoch 64
2024-04-22 14:43:02.963028: Current learning rate: 0.00399
2024-04-22 14:44:55.722244: train_loss -0.627
2024-04-22 14:44:55.722435: val_loss -0.6481
2024-04-22 14:44:55.723331: Pseudo dice [0.8218, 0.7704]
2024-04-22 14:44:55.723386: Epoch time: 112.76 s
2024-04-22 14:44:55.723421: Yayy! New best EMA pseudo Dice: 0.7533
2024-04-22 14:44:58.761629: 
2024-04-22 14:44:58.761776: Epoch 65
2024-04-22 14:44:58.761858: Current learning rate: 0.00389
2024-04-22 14:46:51.528636: train_loss -0.6038
2024-04-22 14:46:51.528815: val_loss -0.6245
2024-04-22 14:46:51.528870: Pseudo dice [0.8155, 0.6634]
2024-04-22 14:46:51.528919: Epoch time: 112.77 s
2024-04-22 14:46:52.397752: 
2024-04-22 14:46:52.397855: Epoch 66
2024-04-22 14:46:52.398009: Current learning rate: 0.00379
2024-04-22 14:48:46.335068: train_loss -0.6231
2024-04-22 14:48:46.335245: val_loss -0.6366
2024-04-22 14:48:46.335288: Pseudo dice [0.8295, 0.721]
2024-04-22 14:48:46.335335: Epoch time: 113.94 s
2024-04-22 14:48:46.335370: Yayy! New best EMA pseudo Dice: 0.7542
2024-04-22 14:48:48.895432: 
2024-04-22 14:48:48.895576: Epoch 67
2024-04-22 14:48:48.895655: Current learning rate: 0.00369
2024-04-22 14:50:41.991215: train_loss -0.609
2024-04-22 14:50:41.991376: val_loss -0.5989
2024-04-22 14:50:41.991422: Pseudo dice [0.7942, 0.7239]
2024-04-22 14:50:41.991471: Epoch time: 113.1 s
2024-04-22 14:50:41.991506: Yayy! New best EMA pseudo Dice: 0.7547
2024-04-22 14:50:45.102807: 
2024-04-22 14:50:45.102911: Epoch 68
2024-04-22 14:50:45.102994: Current learning rate: 0.00359
2024-04-22 14:52:37.774954: train_loss -0.6202
2024-04-22 14:52:37.775117: val_loss -0.5983
2024-04-22 14:52:37.775161: Pseudo dice [0.8006, 0.6792]
2024-04-22 14:52:37.775209: Epoch time: 112.67 s
2024-04-22 14:52:38.889252: 
2024-04-22 14:52:38.889380: Epoch 69
2024-04-22 14:52:38.889468: Current learning rate: 0.00349
2024-04-22 14:54:32.849618: train_loss -0.6215
2024-04-22 14:54:32.849802: val_loss -0.6354
2024-04-22 14:54:32.849849: Pseudo dice [0.8322, 0.7598]
2024-04-22 14:54:32.849897: Epoch time: 113.96 s
2024-04-22 14:54:32.849930: Yayy! New best EMA pseudo Dice: 0.7575
2024-04-22 14:54:36.217645: 
2024-04-22 14:54:36.217755: Epoch 70
2024-04-22 14:54:36.217838: Current learning rate: 0.00338
2024-04-22 14:56:28.615894: train_loss -0.6106
2024-04-22 14:56:28.616045: val_loss -0.6321
2024-04-22 14:56:28.616088: Pseudo dice [0.8302, 0.7103]
2024-04-22 14:56:28.616141: Epoch time: 112.4 s
2024-04-22 14:56:28.616179: Yayy! New best EMA pseudo Dice: 0.7588
2024-04-22 14:56:32.811258: 
2024-04-22 14:56:32.811369: Epoch 71
2024-04-22 14:56:32.811446: Current learning rate: 0.00328
2024-04-22 14:58:25.043215: train_loss -0.627
2024-04-22 14:58:25.043377: val_loss -0.5929
2024-04-22 14:58:25.043422: Pseudo dice [0.8126, 0.6911]
2024-04-22 14:58:25.043474: Epoch time: 112.23 s
2024-04-22 14:58:25.938135: 
2024-04-22 14:58:25.938243: Epoch 72
2024-04-22 14:58:25.938323: Current learning rate: 0.00318
2024-04-22 15:00:19.886120: train_loss -0.6302
2024-04-22 15:00:19.886256: val_loss -0.5817
2024-04-22 15:00:19.886302: Pseudo dice [0.8017, 0.6882]
2024-04-22 15:00:19.886358: Epoch time: 113.95 s
2024-04-22 15:00:20.774644: 
2024-04-22 15:00:20.774762: Epoch 73
2024-04-22 15:00:20.774845: Current learning rate: 0.00308
2024-04-22 15:02:14.527703: train_loss -0.6212
2024-04-22 15:02:14.527852: val_loss -0.599
2024-04-22 15:02:14.527894: Pseudo dice [0.7997, 0.7098]
2024-04-22 15:02:14.527942: Epoch time: 113.75 s
2024-04-22 15:02:15.416215: 
2024-04-22 15:02:15.416396: Epoch 74
2024-04-22 15:02:15.416486: Current learning rate: 0.00297
2024-04-22 15:04:09.425340: train_loss -0.6328
2024-04-22 15:04:09.425535: val_loss -0.5895
2024-04-22 15:04:09.425580: Pseudo dice [0.813, 0.6881]
2024-04-22 15:04:09.425637: Epoch time: 114.01 s
2024-04-22 15:04:10.502057: 
2024-04-22 15:04:10.502169: Epoch 75
2024-04-22 15:04:10.502249: Current learning rate: 0.00287
2024-04-22 15:06:04.555615: train_loss -0.6181
2024-04-22 15:06:04.555805: val_loss -0.6262
2024-04-22 15:06:04.555847: Pseudo dice [0.832, 0.7317]
2024-04-22 15:06:04.555897: Epoch time: 114.05 s
2024-04-22 15:06:05.454882: 
2024-04-22 15:06:05.454988: Epoch 76
2024-04-22 15:06:05.455070: Current learning rate: 0.00277
2024-04-22 15:07:59.108048: train_loss -0.6239
2024-04-22 15:07:59.108205: val_loss -0.6612
2024-04-22 15:07:59.108247: Pseudo dice [0.8475, 0.7317]
2024-04-22 15:07:59.108292: Epoch time: 113.65 s
2024-04-22 15:07:59.108326: Yayy! New best EMA pseudo Dice: 0.7617
2024-04-22 15:08:02.365058: 
2024-04-22 15:08:02.365181: Epoch 77
2024-04-22 15:08:02.365265: Current learning rate: 0.00266
2024-04-22 15:09:55.429341: train_loss -0.6347
2024-04-22 15:09:55.429499: val_loss -0.6236
2024-04-22 15:09:55.429543: Pseudo dice [0.8116, 0.7287]
2024-04-22 15:09:55.429590: Epoch time: 113.07 s
2024-04-22 15:09:55.429626: Yayy! New best EMA pseudo Dice: 0.7625
2024-04-22 15:09:59.435843: 
2024-04-22 15:09:59.435964: Epoch 78
2024-04-22 15:09:59.436048: Current learning rate: 0.00256
2024-04-22 15:11:52.007225: train_loss -0.6253
2024-04-22 15:11:52.007372: val_loss -0.6291
2024-04-22 15:11:52.007414: Pseudo dice [0.8472, 0.6889]
2024-04-22 15:11:52.007460: Epoch time: 112.57 s
2024-04-22 15:11:52.007494: Yayy! New best EMA pseudo Dice: 0.7631
2024-04-22 15:11:55.315624: 
2024-04-22 15:11:55.315739: Epoch 79
2024-04-22 15:11:55.315824: Current learning rate: 0.00245
2024-04-22 15:13:48.133600: train_loss -0.6315
2024-04-22 15:13:48.133744: val_loss -0.6421
2024-04-22 15:13:48.133788: Pseudo dice [0.8135, 0.7066]
2024-04-22 15:13:48.133836: Epoch time: 112.82 s
2024-04-22 15:13:49.214250: 
2024-04-22 15:13:49.214362: Epoch 80
2024-04-22 15:13:49.214448: Current learning rate: 0.00235
2024-04-22 15:15:43.506497: train_loss -0.6342
2024-04-22 15:15:43.506692: val_loss -0.6354
2024-04-22 15:15:43.506737: Pseudo dice [0.8403, 0.6949]
2024-04-22 15:15:43.506785: Epoch time: 114.29 s
2024-04-22 15:15:43.506819: Yayy! New best EMA pseudo Dice: 0.7632
2024-04-22 15:15:47.155693: 
2024-04-22 15:15:47.155794: Epoch 81
2024-04-22 15:15:47.155885: Current learning rate: 0.00224
2024-04-22 15:17:39.894658: train_loss -0.6347
2024-04-22 15:17:39.894827: val_loss -0.6362
2024-04-22 15:17:39.894873: Pseudo dice [0.83, 0.7251]
2024-04-22 15:17:39.894922: Epoch time: 112.74 s
2024-04-22 15:17:39.894956: Yayy! New best EMA pseudo Dice: 0.7647
2024-04-22 15:17:42.782031: 
2024-04-22 15:17:42.782243: Epoch 82
2024-04-22 15:17:42.782341: Current learning rate: 0.00214
2024-04-22 15:19:36.253468: train_loss -0.6241
2024-04-22 15:19:36.253677: val_loss -0.6347
2024-04-22 15:19:36.253722: Pseudo dice [0.8275, 0.6892]
2024-04-22 15:19:36.253771: Epoch time: 113.47 s
2024-04-22 15:19:37.107274: 
2024-04-22 15:19:37.107368: Epoch 83
2024-04-22 15:19:37.107448: Current learning rate: 0.00203
2024-04-22 15:21:31.566515: train_loss -0.6352
2024-04-22 15:21:31.566679: val_loss -0.6165
2024-04-22 15:21:31.566721: Pseudo dice [0.8326, 0.7027]
2024-04-22 15:21:31.566769: Epoch time: 114.46 s
2024-04-22 15:21:32.410865: 
2024-04-22 15:21:32.410981: Epoch 84
2024-04-22 15:21:32.411062: Current learning rate: 0.00192
2024-04-22 15:23:27.013377: train_loss -0.6274
2024-04-22 15:23:27.013535: val_loss -0.6063
2024-04-22 15:23:27.013578: Pseudo dice [0.8387, 0.7029]
2024-04-22 15:23:27.013625: Epoch time: 114.6 s
2024-04-22 15:23:27.013661: Yayy! New best EMA pseudo Dice: 0.765
2024-04-22 15:23:30.642360: 
2024-04-22 15:23:30.642474: Epoch 85
2024-04-22 15:23:30.642554: Current learning rate: 0.00181
2024-04-22 15:25:23.830083: train_loss -0.62
2024-04-22 15:25:23.830258: val_loss -0.6118
2024-04-22 15:25:23.830299: Pseudo dice [0.8207, 0.7206]
2024-04-22 15:25:23.830354: Epoch time: 113.19 s
2024-04-22 15:25:23.830389: Yayy! New best EMA pseudo Dice: 0.7656
2024-04-22 15:25:27.317352: 
2024-04-22 15:25:27.317465: Epoch 86
2024-04-22 15:25:27.317549: Current learning rate: 0.0017
2024-04-22 15:27:20.187355: train_loss -0.6347
2024-04-22 15:27:20.187553: val_loss -0.6402
2024-04-22 15:27:20.187600: Pseudo dice [0.8375, 0.7471]
2024-04-22 15:27:20.187654: Epoch time: 112.87 s
2024-04-22 15:27:20.187689: Yayy! New best EMA pseudo Dice: 0.7683
2024-04-22 15:27:23.328533: 
2024-04-22 15:27:23.328648: Epoch 87
2024-04-22 15:27:23.328727: Current learning rate: 0.00159
2024-04-22 15:29:16.785912: train_loss -0.6348
2024-04-22 15:29:16.786069: val_loss -0.6227
2024-04-22 15:29:16.786118: Pseudo dice [0.8088, 0.6981]
2024-04-22 15:29:16.786168: Epoch time: 113.46 s
2024-04-22 15:29:17.630697: 
2024-04-22 15:29:17.630791: Epoch 88
2024-04-22 15:29:17.630871: Current learning rate: 0.00148
2024-04-22 15:31:12.002994: train_loss -0.6247
2024-04-22 15:31:12.003186: val_loss -0.6182
2024-04-22 15:31:12.003232: Pseudo dice [0.8081, 0.7115]
2024-04-22 15:31:12.003280: Epoch time: 114.37 s
2024-04-22 15:31:12.842129: 
2024-04-22 15:31:12.842242: Epoch 89
2024-04-22 15:31:12.842397: Current learning rate: 0.00137
2024-04-22 15:33:06.885385: train_loss -0.6395
2024-04-22 15:33:06.885559: val_loss -0.6339
2024-04-22 15:33:06.885604: Pseudo dice [0.8287, 0.7041]
2024-04-22 15:33:06.885653: Epoch time: 114.04 s
2024-04-22 15:33:07.725652: 
2024-04-22 15:33:07.725770: Epoch 90
2024-04-22 15:33:07.725857: Current learning rate: 0.00126
2024-04-22 15:35:02.141946: train_loss -0.6246
2024-04-22 15:35:02.142082: val_loss -0.6249
2024-04-22 15:35:02.142126: Pseudo dice [0.7918, 0.7268]
2024-04-22 15:35:02.142173: Epoch time: 114.42 s
2024-04-22 15:35:02.977443: 
2024-04-22 15:35:02.977555: Epoch 91
2024-04-22 15:35:02.977639: Current learning rate: 0.00115
2024-04-22 15:36:57.595430: train_loss -0.6393
2024-04-22 15:36:57.595690: val_loss -0.6161
2024-04-22 15:36:57.595738: Pseudo dice [0.811, 0.6676]
2024-04-22 15:36:57.595787: Epoch time: 114.62 s
2024-04-22 15:36:58.430053: 
2024-04-22 15:36:58.430159: Epoch 92
2024-04-22 15:36:58.430238: Current learning rate: 0.00103
2024-04-22 15:38:53.040954: train_loss -0.6317
2024-04-22 15:38:53.041118: val_loss -0.6312
2024-04-22 15:38:53.041159: Pseudo dice [0.8326, 0.7442]
2024-04-22 15:38:53.041205: Epoch time: 114.61 s
2024-04-22 15:38:53.877337: 
2024-04-22 15:38:53.877456: Epoch 93
2024-04-22 15:38:53.877535: Current learning rate: 0.00091
2024-04-22 15:40:48.310206: train_loss -0.6314
2024-04-22 15:40:48.310351: val_loss -0.6218
2024-04-22 15:40:48.310403: Pseudo dice [0.8171, 0.7237]
2024-04-22 15:40:48.310453: Epoch time: 114.43 s
2024-04-22 15:40:49.144272: 
2024-04-22 15:40:49.144384: Epoch 94
2024-04-22 15:40:49.144465: Current learning rate: 0.00079
2024-04-22 15:42:43.937714: train_loss -0.6526
2024-04-22 15:42:43.937913: val_loss -0.6504
2024-04-22 15:42:43.937957: Pseudo dice [0.848, 0.7448]
2024-04-22 15:42:43.938010: Epoch time: 114.79 s
2024-04-22 15:42:43.938044: Yayy! New best EMA pseudo Dice: 0.7689
2024-04-22 15:42:46.711178: 
2024-04-22 15:42:46.711268: Epoch 95
2024-04-22 15:42:46.711349: Current learning rate: 0.00067
2024-04-22 15:44:40.246737: train_loss -0.6296
2024-04-22 15:44:40.246858: val_loss -0.631
2024-04-22 15:44:40.246900: Pseudo dice [0.8226, 0.7456]
2024-04-22 15:44:40.246947: Epoch time: 113.54 s
2024-04-22 15:44:40.246982: Yayy! New best EMA pseudo Dice: 0.7705
2024-04-22 15:44:43.659481: 
2024-04-22 15:44:43.659600: Epoch 96
2024-04-22 15:44:43.659681: Current learning rate: 0.00055
2024-04-22 15:46:36.632351: train_loss -0.6428
2024-04-22 15:46:36.632513: val_loss -0.6086
2024-04-22 15:46:36.632555: Pseudo dice [0.8197, 0.669]
2024-04-22 15:46:36.632605: Epoch time: 112.97 s
2024-04-22 15:46:37.490323: 
2024-04-22 15:46:37.490460: Epoch 97
2024-04-22 15:46:37.490543: Current learning rate: 0.00043
2024-04-22 15:48:31.946413: train_loss -0.6406
2024-04-22 15:48:31.946563: val_loss -0.6132
2024-04-22 15:48:31.946607: Pseudo dice [0.8339, 0.7074]
2024-04-22 15:48:31.946653: Epoch time: 114.46 s
2024-04-22 15:48:32.798149: 
2024-04-22 15:48:32.798260: Epoch 98
2024-04-22 15:48:32.798347: Current learning rate: 0.0003
2024-04-22 15:50:27.427734: train_loss -0.6455
2024-04-22 15:50:27.427881: val_loss -0.6201
2024-04-22 15:50:27.427924: Pseudo dice [0.7892, 0.7506]
2024-04-22 15:50:27.427970: Epoch time: 114.63 s
2024-04-22 15:50:28.467338: 
2024-04-22 15:50:28.467511: Epoch 99
2024-04-22 15:50:28.467617: Current learning rate: 0.00016
2024-04-22 15:52:22.648568: train_loss -0.6368
2024-04-22 15:52:22.648728: val_loss -0.6458
2024-04-22 15:52:22.648770: Pseudo dice [0.8393, 0.709]
2024-04-22 15:52:22.648817: Epoch time: 114.18 s
2024-04-22 15:52:23.899341: Training done.
2024-04-22 15:52:23.910302: Using splits from existing split file: /media/HDD_4TB_2/sergio/TFM/hecktor/hecktor/data/nnUNet_preprocessed/Dataset500_HeadNeckPTCT/splits_final.json
2024-04-22 15:52:23.910996: The split file contains 5 splits.
2024-04-22 15:52:23.911102: Desired fold for training: 4
2024-04-22 15:52:23.911125: This split has 377 training and 94 validation cases.
2024-04-22 15:52:23.911607: predicting CHUM_001
2024-04-22 15:52:23.912326: CHUM_001, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:52:29.776745: predicting CHUM_011
2024-04-22 15:52:29.779271: CHUM_011, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:52:34.107250: predicting CHUM_018
2024-04-22 15:52:34.109861: CHUM_018, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:52:38.501566: predicting CHUM_033
2024-04-22 15:52:38.504740: CHUM_033, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:52:42.914560: predicting CHUM_040
2024-04-22 15:52:42.917176: CHUM_040, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:52:47.313381: predicting CHUM_045
2024-04-22 15:52:47.316161: CHUM_045, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:52:51.732832: predicting CHUM_047
2024-04-22 15:52:51.735790: CHUM_047, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:52:56.135134: predicting CHUM_057
2024-04-22 15:52:56.138021: CHUM_057, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:00.554112: predicting CHUP_006
2024-04-22 15:53:00.557118: CHUP_006, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:04.977992: predicting CHUP_007
2024-04-22 15:53:04.980683: CHUP_007, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:09.389788: predicting CHUP_013
2024-04-22 15:53:09.392872: CHUP_013, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:13.805855: predicting CHUP_015
2024-04-22 15:53:13.808911: CHUP_015, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:18.227610: predicting CHUP_016
2024-04-22 15:53:18.230406: CHUP_016, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:22.649534: predicting CHUP_025
2024-04-22 15:53:22.652112: CHUP_025, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:27.058793: predicting CHUP_027
2024-04-22 15:53:27.061302: CHUP_027, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:31.456252: predicting CHUP_029
2024-04-22 15:53:31.458645: CHUP_029, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:35.858021: predicting CHUP_030
2024-04-22 15:53:35.860638: CHUP_030, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:40.261629: predicting CHUP_035
2024-04-22 15:53:40.264179: CHUP_035, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:44.677181: predicting CHUP_036
2024-04-22 15:53:44.680030: CHUP_036, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:49.068667: predicting CHUP_037
2024-04-22 15:53:49.071535: CHUP_037, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:53.448918: predicting CHUP_038
2024-04-22 15:53:53.451924: CHUP_038, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:53:57.862323: predicting CHUP_047
2024-04-22 15:53:57.865317: CHUP_047, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:02.241751: predicting CHUP_063
2024-04-22 15:54:02.244359: CHUP_063, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:06.655103: predicting CHUP_065
2024-04-22 15:54:06.657945: CHUP_065, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:11.053122: predicting CHUP_066
2024-04-22 15:54:11.055581: CHUP_066, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:15.467061: predicting CHUS_007
2024-04-22 15:54:15.469905: CHUS_007, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:19.860946: predicting CHUS_008
2024-04-22 15:54:19.863674: CHUS_008, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:24.260218: predicting CHUS_016
2024-04-22 15:54:24.262687: CHUS_016, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:28.651193: predicting CHUS_028
2024-04-22 15:54:28.654088: CHUS_028, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:33.053071: predicting CHUS_035
2024-04-22 15:54:33.056109: CHUS_035, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:37.465723: predicting CHUS_042
2024-04-22 15:54:37.468570: CHUS_042, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:41.898409: predicting CHUS_048
2024-04-22 15:54:41.901249: CHUS_048, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:46.316090: predicting CHUS_049
2024-04-22 15:54:46.318498: CHUS_049, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:50.712940: predicting CHUS_052
2024-04-22 15:54:50.716079: CHUS_052, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:55.101455: predicting CHUS_065
2024-04-22 15:54:55.104040: CHUS_065, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:54:59.520680: predicting CHUS_083
2024-04-22 15:54:59.523139: CHUS_083, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:55:03.913445: predicting CHUS_089
2024-04-22 15:55:03.916166: CHUS_089, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:55:08.303535: predicting CHUS_091
2024-04-22 15:55:08.306348: CHUS_091, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:55:12.698884: predicting CHUS_100
2024-04-22 15:55:12.701400: CHUS_100, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:55:17.117652: predicting CHUV_006
2024-04-22 15:55:17.120356: CHUV_006, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:55:21.527296: predicting CHUV_011
2024-04-22 15:55:21.530057: CHUV_011, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:55:25.941188: predicting CHUV_024
2024-04-22 15:55:25.944019: CHUV_024, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:55:30.344765: predicting CHUV_031
2024-04-22 15:55:30.347067: CHUV_031, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:55:34.772074: predicting CHUV_033
2024-04-22 15:55:34.775116: CHUV_033, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:55:39.170310: predicting CHUV_041
2024-04-22 15:55:39.173149: CHUV_041, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:55:43.584624: predicting CHUV_049
2024-04-22 15:55:43.587192: CHUV_049, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:55:47.989890: predicting CHUV_050
2024-04-22 15:55:47.992537: CHUV_050, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:55:52.397579: predicting HGJ_008
2024-04-22 15:55:52.400098: HGJ_008, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:55:56.792006: predicting HGJ_016
2024-04-22 15:55:56.794930: HGJ_016, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:56:01.196399: predicting HGJ_038
2024-04-22 15:56:01.199160: HGJ_038, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:56:05.592933: predicting HGJ_043
2024-04-22 15:56:05.595678: HGJ_043, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:56:09.990365: predicting HGJ_050
2024-04-22 15:56:09.993204: HGJ_050, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:56:14.382393: predicting HGJ_052
2024-04-22 15:56:14.385035: HGJ_052, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:56:18.790736: predicting HGJ_062
2024-04-22 15:56:18.793761: HGJ_062, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:56:23.200057: predicting HGJ_069
2024-04-22 15:56:23.202526: HGJ_069, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:56:27.605706: predicting HGJ_072
2024-04-22 15:56:27.608272: HGJ_072, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:56:31.997791: predicting HGJ_077
2024-04-22 15:56:32.000354: HGJ_077, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:56:36.416016: predicting HGJ_092
2024-04-22 15:56:36.418530: HGJ_092, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:56:40.827011: predicting HMR_001
2024-04-22 15:56:40.829556: HMR_001, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:56:45.225811: predicting HMR_016
2024-04-22 15:56:45.228474: HMR_016, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:56:49.615028: predicting HMR_021
2024-04-22 15:56:49.617917: HMR_021, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:56:54.016225: predicting HMR_023
2024-04-22 15:56:54.018547: HMR_023, shape torch.Size([2, 129, 176, 176]), rank 0
2024-04-22 15:56:58.422035: predicting HMR_034
2024-04-22 15:56:58.424067: HMR_034, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:57:02.833293: predicting MDA_003
2024-04-22 15:57:02.836392: MDA_003, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:57:07.244297: predicting MDA_010
2024-04-22 15:57:07.246870: MDA_010, shape torch.Size([2, 165, 176, 176]), rank 0
2024-04-22 15:57:11.630803: predicting MDA_019
2024-04-22 15:57:11.633587: MDA_019, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:57:16.025321: predicting MDA_025
2024-04-22 15:57:16.027842: MDA_025, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:57:20.458668: predicting MDA_042
2024-04-22 15:57:20.461480: MDA_042, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:57:24.856195: predicting MDA_049
2024-04-22 15:57:24.858897: MDA_049, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:57:29.264483: predicting MDA_056
2024-04-22 15:57:29.267284: MDA_056, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:57:33.657244: predicting MDA_057
2024-04-22 15:57:33.659331: MDA_057, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:57:38.078778: predicting MDA_060
2024-04-22 15:57:38.081623: MDA_060, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:57:42.494255: predicting MDA_068
2024-04-22 15:57:42.496695: MDA_068, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:57:46.897364: predicting MDA_072
2024-04-22 15:57:46.904191: MDA_072, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:57:51.292699: predicting MDA_086
2024-04-22 15:57:51.295255: MDA_086, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:57:55.703031: predicting MDA_087
2024-04-22 15:57:55.705707: MDA_087, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:58:00.092405: predicting MDA_089
2024-04-22 15:58:00.094797: MDA_089, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:58:04.527374: predicting MDA_092
2024-04-22 15:58:04.529897: MDA_092, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:58:08.932445: predicting MDA_097
2024-04-22 15:58:08.934706: MDA_097, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:58:13.316365: predicting MDA_101
2024-04-22 15:58:13.318596: MDA_101, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:58:17.723809: predicting MDA_107
2024-04-22 15:58:17.726349: MDA_107, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:58:22.135141: predicting MDA_109
2024-04-22 15:58:22.137726: MDA_109, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:58:26.537893: predicting MDA_120
2024-04-22 15:58:26.540074: MDA_120, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:58:30.942375: predicting MDA_131
2024-04-22 15:58:30.944999: MDA_131, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:58:35.349515: predicting MDA_138
2024-04-22 15:58:35.352199: MDA_138, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:58:39.766320: predicting MDA_143
2024-04-22 15:58:39.771712: MDA_143, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:58:44.155312: predicting MDA_145
2024-04-22 15:58:44.158205: MDA_145, shape torch.Size([2, 148, 176, 176]), rank 0
2024-04-22 15:58:48.561242: predicting MDA_146
2024-04-22 15:58:48.563737: MDA_146, shape torch.Size([2, 161, 176, 176]), rank 0
2024-04-22 15:58:52.978475: predicting MDA_147
2024-04-22 15:58:52.981013: MDA_147, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:58:57.396589: predicting MDA_148
2024-04-22 15:58:57.399120: MDA_148, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:59:01.796771: predicting MDA_164
2024-04-22 15:59:01.799365: MDA_164, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:59:06.176720: predicting MDA_170
2024-04-22 15:59:06.179192: MDA_170, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:59:10.581628: predicting MDA_193
2024-04-22 15:59:10.583854: MDA_193, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:59:14.996031: predicting MDA_194
2024-04-22 15:59:14.998656: MDA_194, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-22 15:59:25.513986: Validation complete
2024-04-22 15:59:25.514052: Mean Validation Dice:  0.6750236801444198
