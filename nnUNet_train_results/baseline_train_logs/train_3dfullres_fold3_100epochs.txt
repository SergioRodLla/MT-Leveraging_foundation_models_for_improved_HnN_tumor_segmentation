Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################


This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [176.0, 176.0, 176.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['CTNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset500_HeadNeckPTCT', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [176, 176, 176], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3084.078125, 'mean': 37.496119355221374, 'median': 41.667911529541016, 'min': -1075.762939453125, 'percentile_00_5': -132.0876007080078, 'percentile_99_5': 155.04347229003906, 'std': 44.774756195436765}, '1': {'max': 44.05201721191406, 'mean': 6.44351180606988, 'median': 5.461172103881836, 'min': -0.37562260031700134, 'percentile_00_5': 0.867931604385376, 'percentile_99_5': 23.637962341308594, 'std': 4.242073649695497}}} 

2024-04-21 17:50:50.622596: unpacking dataset...
2024-04-21 17:50:53.290153: unpacking done...
2024-04-21 17:50:53.290720: do_dummy_2d_data_aug: False
2024-04-21 17:50:53.292542: Using splits from existing split file: /media/HDD_4TB_2/sergio/TFM/hecktor/hecktor/data/nnUNet_preprocessed/Dataset500_HeadNeckPTCT/splits_final.json
2024-04-21 17:50:53.292799: The split file contains 5 splits.
2024-04-21 17:50:53.292824: Desired fold for training: 3
2024-04-21 17:50:53.292843: This split has 377 training and 94 validation cases.
2024-04-21 17:50:53.298030: Unable to plot network architecture:
2024-04-21 17:50:53.298064: No module named 'IPython'
2024-04-21 17:50:53.301241: 
2024-04-21 17:50:53.301274: Epoch 0
2024-04-21 17:50:53.301322: Current learning rate: 0.01
using pin_memory on device 0
using pin_memory on device 0
2024-04-21 17:52:30.386925: train_loss -0.0993
2024-04-21 17:52:30.387109: val_loss -0.2233
2024-04-21 17:52:30.387158: Pseudo dice [0.2995, 0.236]
2024-04-21 17:52:30.387218: Epoch time: 97.09 s
2024-04-21 17:52:30.387258: Yayy! New best EMA pseudo Dice: 0.2677
2024-04-21 17:52:34.674871: 
2024-04-21 17:52:34.674982: Epoch 1
2024-04-21 17:52:34.675060: Current learning rate: 0.00991
2024-04-21 17:54:17.306495: train_loss -0.3368
2024-04-21 17:54:17.306641: val_loss -0.484
2024-04-21 17:54:17.306684: Pseudo dice [0.6845, 0.6302]
2024-04-21 17:54:17.306731: Epoch time: 102.63 s
2024-04-21 17:54:17.306764: Yayy! New best EMA pseudo Dice: 0.3067
2024-04-21 17:54:21.221476: 
2024-04-21 17:54:21.221583: Epoch 2
2024-04-21 17:54:21.221664: Current learning rate: 0.00982
2024-04-21 17:56:07.462379: train_loss -0.4443
2024-04-21 17:56:07.462559: val_loss -0.4529
2024-04-21 17:56:07.462604: Pseudo dice [0.6719, 0.6552]
2024-04-21 17:56:07.462656: Epoch time: 106.24 s
2024-04-21 17:56:07.462690: Yayy! New best EMA pseudo Dice: 0.3424
2024-04-21 17:56:12.305566: 
2024-04-21 17:56:12.305683: Epoch 3
2024-04-21 17:56:12.305769: Current learning rate: 0.00973
2024-04-21 17:57:59.151485: train_loss -0.4921
2024-04-21 17:57:59.151668: val_loss -0.515
2024-04-21 17:57:59.151711: Pseudo dice [0.7202, 0.6985]
2024-04-21 17:57:59.151762: Epoch time: 106.85 s
2024-04-21 17:57:59.151796: Yayy! New best EMA pseudo Dice: 0.3791
2024-04-21 17:58:02.855523: 
2024-04-21 17:58:02.855623: Epoch 4
2024-04-21 17:58:02.855717: Current learning rate: 0.00964
2024-04-21 17:59:51.034392: train_loss -0.4848
2024-04-21 17:59:51.034581: val_loss -0.5014
2024-04-21 17:59:51.034625: Pseudo dice [0.752, 0.6351]
2024-04-21 17:59:51.034675: Epoch time: 108.18 s
2024-04-21 17:59:51.034711: Yayy! New best EMA pseudo Dice: 0.4105
2024-04-21 17:59:54.208900: 
2024-04-21 17:59:54.208994: Epoch 5
2024-04-21 17:59:54.209077: Current learning rate: 0.00955
2024-04-21 18:01:43.134997: train_loss -0.492
2024-04-21 18:01:43.135156: val_loss -0.4875
2024-04-21 18:01:43.135201: Pseudo dice [0.7423, 0.6765]
2024-04-21 18:01:43.135249: Epoch time: 108.93 s
2024-04-21 18:01:43.135284: Yayy! New best EMA pseudo Dice: 0.4404
2024-04-21 18:01:46.232991: 
2024-04-21 18:01:46.233092: Epoch 6
2024-04-21 18:01:46.233176: Current learning rate: 0.00946
2024-04-21 18:03:35.631213: train_loss -0.5077
2024-04-21 18:03:35.631392: val_loss -0.5319
2024-04-21 18:03:35.631438: Pseudo dice [0.7359, 0.6732]
2024-04-21 18:03:35.631490: Epoch time: 109.4 s
2024-04-21 18:03:35.631524: Yayy! New best EMA pseudo Dice: 0.4668
2024-04-21 18:03:38.865574: 
2024-04-21 18:03:38.865682: Epoch 7
2024-04-21 18:03:38.865764: Current learning rate: 0.00937
2024-04-21 18:05:28.723471: train_loss -0.5165
2024-04-21 18:05:28.723606: val_loss -0.5309
2024-04-21 18:05:28.723647: Pseudo dice [0.7755, 0.6977]
2024-04-21 18:05:28.723693: Epoch time: 109.86 s
2024-04-21 18:05:28.723725: Yayy! New best EMA pseudo Dice: 0.4938
2024-04-21 18:05:32.306009: 
2024-04-21 18:05:32.306113: Epoch 8
2024-04-21 18:05:32.306192: Current learning rate: 0.00928
2024-04-21 18:07:22.544578: train_loss -0.5088
2024-04-21 18:07:22.544724: val_loss -0.5384
2024-04-21 18:07:22.544766: Pseudo dice [0.7798, 0.6796]
2024-04-21 18:07:22.544817: Epoch time: 110.24 s
2024-04-21 18:07:22.544850: Yayy! New best EMA pseudo Dice: 0.5174
2024-04-21 18:07:25.989964: 
2024-04-21 18:07:25.990075: Epoch 9
2024-04-21 18:07:25.990161: Current learning rate: 0.00919
2024-04-21 18:09:16.846524: train_loss -0.5244
2024-04-21 18:09:16.846661: val_loss -0.5284
2024-04-21 18:09:16.846705: Pseudo dice [0.7469, 0.6867]
2024-04-21 18:09:16.846752: Epoch time: 110.86 s
2024-04-21 18:09:16.846784: Yayy! New best EMA pseudo Dice: 0.5373
2024-04-21 18:09:21.077051: 
2024-04-21 18:09:21.077170: Epoch 10
2024-04-21 18:09:21.077255: Current learning rate: 0.0091
2024-04-21 18:11:11.884133: train_loss -0.5355
2024-04-21 18:11:11.884278: val_loss -0.542
2024-04-21 18:11:11.884321: Pseudo dice [0.773, 0.6864]
2024-04-21 18:11:11.884369: Epoch time: 110.81 s
2024-04-21 18:11:11.884405: Yayy! New best EMA pseudo Dice: 0.5566
2024-04-21 18:11:15.245850: 
2024-04-21 18:11:15.245940: Epoch 11
2024-04-21 18:11:15.246021: Current learning rate: 0.009
2024-04-21 18:13:06.671426: train_loss -0.5311
2024-04-21 18:13:06.671581: val_loss -0.5355
2024-04-21 18:13:06.671624: Pseudo dice [0.7841, 0.7004]
2024-04-21 18:13:06.671669: Epoch time: 111.43 s
2024-04-21 18:13:06.671701: Yayy! New best EMA pseudo Dice: 0.5751
2024-04-21 18:13:09.970028: 
2024-04-21 18:13:09.970134: Epoch 12
2024-04-21 18:13:09.970211: Current learning rate: 0.00891
2024-04-21 18:15:01.029013: train_loss -0.5515
2024-04-21 18:15:01.029161: val_loss -0.5874
2024-04-21 18:15:01.029204: Pseudo dice [0.7864, 0.7297]
2024-04-21 18:15:01.029250: Epoch time: 111.06 s
2024-04-21 18:15:01.029282: Yayy! New best EMA pseudo Dice: 0.5934
2024-04-21 18:15:04.310636: 
2024-04-21 18:15:04.310739: Epoch 13
2024-04-21 18:15:04.310825: Current learning rate: 0.00882
2024-04-21 18:16:55.958298: train_loss -0.5252
2024-04-21 18:16:55.958471: val_loss -0.5742
2024-04-21 18:16:55.958514: Pseudo dice [0.7943, 0.7224]
2024-04-21 18:16:55.958562: Epoch time: 111.65 s
2024-04-21 18:16:55.958596: Yayy! New best EMA pseudo Dice: 0.6099
2024-04-21 18:17:00.028386: 
2024-04-21 18:17:00.028529: Epoch 14
2024-04-21 18:17:00.028615: Current learning rate: 0.00873
2024-04-21 18:18:51.227035: train_loss -0.5189
2024-04-21 18:18:51.227190: val_loss -0.5575
2024-04-21 18:18:51.227231: Pseudo dice [0.7931, 0.6883]
2024-04-21 18:18:51.227277: Epoch time: 111.2 s
2024-04-21 18:18:51.227310: Yayy! New best EMA pseudo Dice: 0.623
2024-04-21 18:18:54.868219: 
2024-04-21 18:18:54.868324: Epoch 15
2024-04-21 18:18:54.868405: Current learning rate: 0.00864
2024-04-21 18:20:46.573778: train_loss -0.5456
2024-04-21 18:20:46.573928: val_loss -0.5717
2024-04-21 18:20:46.573970: Pseudo dice [0.7861, 0.7118]
2024-04-21 18:20:46.574016: Epoch time: 111.71 s
2024-04-21 18:20:46.574055: Yayy! New best EMA pseudo Dice: 0.6356
2024-04-21 18:20:51.333906: 
2024-04-21 18:20:51.333996: Epoch 16
2024-04-21 18:20:51.334073: Current learning rate: 0.00855
2024-04-21 18:22:42.263623: train_loss -0.553
2024-04-21 18:22:42.263773: val_loss -0.5662
2024-04-21 18:22:42.263818: Pseudo dice [0.796, 0.6654]
2024-04-21 18:22:42.263864: Epoch time: 110.93 s
2024-04-21 18:22:42.263897: Yayy! New best EMA pseudo Dice: 0.6451
2024-04-21 18:22:46.249163: 
2024-04-21 18:22:46.249258: Epoch 17
2024-04-21 18:22:46.249341: Current learning rate: 0.00846
2024-04-21 18:24:37.722648: train_loss -0.5673
2024-04-21 18:24:37.722799: val_loss -0.5659
2024-04-21 18:24:37.722842: Pseudo dice [0.8254, 0.7219]
2024-04-21 18:24:37.722889: Epoch time: 111.47 s
2024-04-21 18:24:37.722922: Yayy! New best EMA pseudo Dice: 0.658
2024-04-21 18:24:42.114721: 
2024-04-21 18:24:42.114823: Epoch 18
2024-04-21 18:24:42.114904: Current learning rate: 0.00836
2024-04-21 18:26:33.864318: train_loss -0.5416
2024-04-21 18:26:33.864507: val_loss -0.5353
2024-04-21 18:26:33.864551: Pseudo dice [0.7425, 0.7135]
2024-04-21 18:26:33.864598: Epoch time: 111.75 s
2024-04-21 18:26:33.864635: Yayy! New best EMA pseudo Dice: 0.665
2024-04-21 18:26:36.870032: 
2024-04-21 18:26:36.870138: Epoch 19
2024-04-21 18:26:36.870218: Current learning rate: 0.00827
2024-04-21 18:28:28.721549: train_loss -0.5569
2024-04-21 18:28:28.721709: val_loss -0.5567
2024-04-21 18:28:28.721750: Pseudo dice [0.774, 0.7022]
2024-04-21 18:28:28.721801: Epoch time: 111.85 s
2024-04-21 18:28:28.721835: Yayy! New best EMA pseudo Dice: 0.6723
2024-04-21 18:28:32.107343: 
2024-04-21 18:28:32.107461: Epoch 20
2024-04-21 18:28:32.107571: Current learning rate: 0.00818
2024-04-21 18:30:23.906904: train_loss -0.5536
2024-04-21 18:30:23.907050: val_loss -0.5733
2024-04-21 18:30:23.907093: Pseudo dice [0.8299, 0.6848]
2024-04-21 18:30:23.907139: Epoch time: 111.8 s
2024-04-21 18:30:23.907173: Yayy! New best EMA pseudo Dice: 0.6808
2024-04-21 18:30:26.813621: 
2024-04-21 18:30:26.813735: Epoch 21
2024-04-21 18:30:26.813821: Current learning rate: 0.00809
2024-04-21 18:32:18.951237: train_loss -0.5616
2024-04-21 18:32:18.951493: val_loss -0.556
2024-04-21 18:32:18.951539: Pseudo dice [0.8076, 0.7073]
2024-04-21 18:32:18.951601: Epoch time: 112.14 s
2024-04-21 18:32:18.951639: Yayy! New best EMA pseudo Dice: 0.6884
2024-04-21 18:32:22.728797: 
2024-04-21 18:32:22.728913: Epoch 22
2024-04-21 18:32:22.728996: Current learning rate: 0.008
2024-04-21 18:34:14.473906: train_loss -0.5612
2024-04-21 18:34:14.474076: val_loss -0.5594
2024-04-21 18:34:14.474118: Pseudo dice [0.8033, 0.6826]
2024-04-21 18:34:14.474164: Epoch time: 111.75 s
2024-04-21 18:34:14.474197: Yayy! New best EMA pseudo Dice: 0.6939
2024-04-21 18:34:17.742792: 
2024-04-21 18:34:17.742880: Epoch 23
2024-04-21 18:34:17.742962: Current learning rate: 0.0079
2024-04-21 18:36:10.036833: train_loss -0.5512
2024-04-21 18:36:10.036972: val_loss -0.5892
2024-04-21 18:36:10.037015: Pseudo dice [0.7974, 0.7334]
2024-04-21 18:36:10.037061: Epoch time: 112.29 s
2024-04-21 18:36:10.037094: Yayy! New best EMA pseudo Dice: 0.701
2024-04-21 18:36:13.320822: 
2024-04-21 18:36:13.320934: Epoch 24
2024-04-21 18:36:13.321020: Current learning rate: 0.00781
2024-04-21 18:38:05.824412: train_loss -0.5578
2024-04-21 18:38:05.824587: val_loss -0.565
2024-04-21 18:38:05.824630: Pseudo dice [0.7646, 0.7216]
2024-04-21 18:38:05.824677: Epoch time: 112.5 s
2024-04-21 18:38:05.824711: Yayy! New best EMA pseudo Dice: 0.7052
2024-04-21 18:38:09.166518: 
2024-04-21 18:38:09.166621: Epoch 25
2024-04-21 18:38:09.166705: Current learning rate: 0.00772
2024-04-21 18:40:01.686327: train_loss -0.5665
2024-04-21 18:40:01.686538: val_loss -0.5765
2024-04-21 18:40:01.686581: Pseudo dice [0.7813, 0.6977]
2024-04-21 18:40:01.686632: Epoch time: 112.52 s
2024-04-21 18:40:01.686667: Yayy! New best EMA pseudo Dice: 0.7087
2024-04-21 18:40:05.566561: 
2024-04-21 18:40:05.566679: Epoch 26
2024-04-21 18:40:05.566768: Current learning rate: 0.00763
2024-04-21 18:41:57.871027: train_loss -0.5537
2024-04-21 18:41:57.871178: val_loss -0.5768
2024-04-21 18:41:57.871221: Pseudo dice [0.7799, 0.7389]
2024-04-21 18:41:57.871271: Epoch time: 112.31 s
2024-04-21 18:41:57.871306: Yayy! New best EMA pseudo Dice: 0.7137
2024-04-21 18:42:00.736162: 
2024-04-21 18:42:00.736277: Epoch 27
2024-04-21 18:42:00.736363: Current learning rate: 0.00753
2024-04-21 18:43:53.368451: train_loss -0.5577
2024-04-21 18:43:53.368591: val_loss -0.6224
2024-04-21 18:43:53.368633: Pseudo dice [0.8168, 0.7336]
2024-04-21 18:43:53.368679: Epoch time: 112.63 s
2024-04-21 18:43:53.368711: Yayy! New best EMA pseudo Dice: 0.7199
2024-04-21 18:43:57.599288: 
2024-04-21 18:43:57.599405: Epoch 28
2024-04-21 18:43:57.599489: Current learning rate: 0.00744
2024-04-21 18:45:49.541191: train_loss -0.5531
2024-04-21 18:45:49.541351: val_loss -0.5922
2024-04-21 18:45:49.541400: Pseudo dice [0.783, 0.729]
2024-04-21 18:45:49.541446: Epoch time: 111.94 s
2024-04-21 18:45:49.541480: Yayy! New best EMA pseudo Dice: 0.7235
2024-04-21 18:45:53.647270: 
2024-04-21 18:45:53.647385: Epoch 29
2024-04-21 18:45:53.647463: Current learning rate: 0.00735
2024-04-21 18:47:45.410228: train_loss -0.5807
2024-04-21 18:47:45.410402: val_loss -0.5916
2024-04-21 18:47:45.410457: Pseudo dice [0.8096, 0.7423]
2024-04-21 18:47:45.410512: Epoch time: 111.76 s
2024-04-21 18:47:45.410555: Yayy! New best EMA pseudo Dice: 0.7288
2024-04-21 18:47:49.780490: 
2024-04-21 18:47:49.780663: Epoch 30
2024-04-21 18:47:49.780784: Current learning rate: 0.00725
2024-04-21 18:49:41.831506: train_loss -0.5533
2024-04-21 18:49:41.831636: val_loss -0.5644
2024-04-21 18:49:41.831679: Pseudo dice [0.8021, 0.7144]
2024-04-21 18:49:41.831727: Epoch time: 112.05 s
2024-04-21 18:49:41.831761: Yayy! New best EMA pseudo Dice: 0.7317
2024-04-21 18:49:45.204038: 
2024-04-21 18:49:45.204127: Epoch 31
2024-04-21 18:49:45.204205: Current learning rate: 0.00716
2024-04-21 18:51:37.557592: train_loss -0.578
2024-04-21 18:51:37.557790: val_loss -0.5734
2024-04-21 18:51:37.557834: Pseudo dice [0.8123, 0.6913]
2024-04-21 18:51:37.557883: Epoch time: 112.35 s
2024-04-21 18:51:37.557920: Yayy! New best EMA pseudo Dice: 0.7337
2024-04-21 18:51:41.173692: 
2024-04-21 18:51:41.173793: Epoch 32
2024-04-21 18:51:41.173877: Current learning rate: 0.00707
2024-04-21 18:53:33.117512: train_loss -0.5662
2024-04-21 18:53:33.117637: val_loss -0.5813
2024-04-21 18:53:33.117678: Pseudo dice [0.8121, 0.6865]
2024-04-21 18:53:33.117723: Epoch time: 111.94 s
2024-04-21 18:53:33.117756: Yayy! New best EMA pseudo Dice: 0.7353
2024-04-21 18:53:37.241642: 
2024-04-21 18:53:37.241748: Epoch 33
2024-04-21 18:53:37.241828: Current learning rate: 0.00697
2024-04-21 18:55:28.797291: train_loss -0.5809
2024-04-21 18:55:28.797453: val_loss -0.5477
2024-04-21 18:55:28.797497: Pseudo dice [0.7885, 0.7037]
2024-04-21 18:55:28.797544: Epoch time: 111.56 s
2024-04-21 18:55:28.797577: Yayy! New best EMA pseudo Dice: 0.7364
2024-04-21 18:55:33.749073: 
2024-04-21 18:55:33.749178: Epoch 34
2024-04-21 18:55:33.749256: Current learning rate: 0.00688
2024-04-21 18:57:25.222701: train_loss -0.5676
2024-04-21 18:57:25.222876: val_loss -0.5878
2024-04-21 18:57:25.222922: Pseudo dice [0.7849, 0.7465]
2024-04-21 18:57:25.222969: Epoch time: 111.47 s
2024-04-21 18:57:25.223003: Yayy! New best EMA pseudo Dice: 0.7393
2024-04-21 18:57:30.114577: 
2024-04-21 18:57:30.114693: Epoch 35
2024-04-21 18:57:30.114775: Current learning rate: 0.00679
2024-04-21 18:59:21.624715: train_loss -0.5955
2024-04-21 18:59:21.624862: val_loss -0.5728
2024-04-21 18:59:21.624905: Pseudo dice [0.7808, 0.7266]
2024-04-21 18:59:21.624950: Epoch time: 111.51 s
2024-04-21 18:59:21.624984: Yayy! New best EMA pseudo Dice: 0.7407
2024-04-21 18:59:25.003163: 
2024-04-21 18:59:25.003280: Epoch 36
2024-04-21 18:59:25.003358: Current learning rate: 0.00669
2024-04-21 19:01:17.077107: train_loss -0.5608
2024-04-21 19:01:17.077285: val_loss -0.58
2024-04-21 19:01:17.077328: Pseudo dice [0.8011, 0.7132]
2024-04-21 19:01:17.077375: Epoch time: 112.07 s
2024-04-21 19:01:17.077409: Yayy! New best EMA pseudo Dice: 0.7424
2024-04-21 19:01:20.876074: 
2024-04-21 19:01:20.876207: Epoch 37
2024-04-21 19:01:20.876293: Current learning rate: 0.0066
2024-04-21 19:03:12.553303: train_loss -0.5705
2024-04-21 19:03:12.553438: val_loss -0.5834
2024-04-21 19:03:12.553481: Pseudo dice [0.7861, 0.7315]
2024-04-21 19:03:12.553525: Epoch time: 111.68 s
2024-04-21 19:03:12.553560: Yayy! New best EMA pseudo Dice: 0.744
2024-04-21 19:03:15.896288: 
2024-04-21 19:03:15.896395: Epoch 38
2024-04-21 19:03:15.896476: Current learning rate: 0.0065
2024-04-21 19:05:07.712579: train_loss -0.5951
2024-04-21 19:05:07.712725: val_loss -0.6097
2024-04-21 19:05:07.712771: Pseudo dice [0.7921, 0.7486]
2024-04-21 19:05:07.712818: Epoch time: 111.82 s
2024-04-21 19:05:07.712850: Yayy! New best EMA pseudo Dice: 0.7467
2024-04-21 19:05:12.119101: 
2024-04-21 19:05:12.119203: Epoch 39
2024-04-21 19:05:12.119286: Current learning rate: 0.00641
2024-04-21 19:07:03.474079: train_loss -0.5753
2024-04-21 19:07:03.474236: val_loss -0.5988
2024-04-21 19:07:03.474282: Pseudo dice [0.8415, 0.6726]
2024-04-21 19:07:03.474330: Epoch time: 111.36 s
2024-04-21 19:07:03.474370: Yayy! New best EMA pseudo Dice: 0.7477
2024-04-21 19:07:08.595397: 
2024-04-21 19:07:08.595514: Epoch 40
2024-04-21 19:07:08.595597: Current learning rate: 0.00631
2024-04-21 19:08:59.827353: train_loss -0.5864
2024-04-21 19:08:59.827552: val_loss -0.5835
2024-04-21 19:08:59.827597: Pseudo dice [0.799, 0.7314]
2024-04-21 19:08:59.827651: Epoch time: 111.23 s
2024-04-21 19:08:59.827686: Yayy! New best EMA pseudo Dice: 0.7494
2024-04-21 19:09:03.303047: 
2024-04-21 19:09:03.303190: Epoch 41
2024-04-21 19:09:03.303270: Current learning rate: 0.00622
2024-04-21 19:10:54.970384: train_loss -0.5902
2024-04-21 19:10:54.970555: val_loss -0.6075
2024-04-21 19:10:54.970599: Pseudo dice [0.8214, 0.738]
2024-04-21 19:10:54.970647: Epoch time: 111.67 s
2024-04-21 19:10:54.970680: Yayy! New best EMA pseudo Dice: 0.7525
2024-04-21 19:10:58.939412: 
2024-04-21 19:10:58.939523: Epoch 42
2024-04-21 19:10:58.939604: Current learning rate: 0.00612
2024-04-21 19:12:50.714503: train_loss -0.5973
2024-04-21 19:12:50.714712: val_loss -0.5772
2024-04-21 19:12:50.714755: Pseudo dice [0.8119, 0.6964]
2024-04-21 19:12:50.714803: Epoch time: 111.78 s
2024-04-21 19:12:50.714835: Yayy! New best EMA pseudo Dice: 0.7526
2024-04-21 19:12:54.102424: 
2024-04-21 19:12:54.102643: Epoch 43
2024-04-21 19:12:54.102739: Current learning rate: 0.00603
2024-04-21 19:14:46.270144: train_loss -0.5855
2024-04-21 19:14:46.270303: val_loss -0.6134
2024-04-21 19:14:46.270353: Pseudo dice [0.825, 0.6933]
2024-04-21 19:14:46.270403: Epoch time: 112.17 s
2024-04-21 19:14:46.270438: Yayy! New best EMA pseudo Dice: 0.7533
2024-04-21 19:14:49.448628: 
2024-04-21 19:14:49.448733: Epoch 44
2024-04-21 19:14:49.448817: Current learning rate: 0.00593
2024-04-21 19:16:41.803537: train_loss -0.59
2024-04-21 19:16:41.803687: val_loss -0.5493
2024-04-21 19:16:41.803730: Pseudo dice [0.8027, 0.6782]
2024-04-21 19:16:41.803777: Epoch time: 112.36 s
2024-04-21 19:16:42.867306: 
2024-04-21 19:16:42.867519: Epoch 45
2024-04-21 19:16:42.867615: Current learning rate: 0.00584
2024-04-21 19:18:36.306586: train_loss -0.5892
2024-04-21 19:18:36.306735: val_loss -0.5972
2024-04-21 19:18:36.306777: Pseudo dice [0.789, 0.7236]
2024-04-21 19:18:36.306823: Epoch time: 113.44 s
2024-04-21 19:18:37.127519: 
2024-04-21 19:18:37.127654: Epoch 46
2024-04-21 19:18:37.127734: Current learning rate: 0.00574
2024-04-21 19:20:30.840238: train_loss -0.5901
2024-04-21 19:20:30.840409: val_loss -0.5343
2024-04-21 19:20:30.840453: Pseudo dice [0.7689, 0.6742]
2024-04-21 19:20:30.840500: Epoch time: 113.71 s
2024-04-21 19:20:31.673548: 
2024-04-21 19:20:31.673666: Epoch 47
2024-04-21 19:20:31.673748: Current learning rate: 0.00565
2024-04-21 19:22:25.270147: train_loss -0.5777
2024-04-21 19:22:25.270323: val_loss -0.6168
2024-04-21 19:22:25.270380: Pseudo dice [0.8285, 0.7187]
2024-04-21 19:22:25.270433: Epoch time: 113.6 s
2024-04-21 19:22:26.100369: 
2024-04-21 19:22:26.100467: Epoch 48
2024-04-21 19:22:26.100547: Current learning rate: 0.00555
2024-04-21 19:24:19.783477: train_loss -0.5857
2024-04-21 19:24:19.783638: val_loss -0.6149
2024-04-21 19:24:19.783683: Pseudo dice [0.7767, 0.7575]
2024-04-21 19:24:19.783731: Epoch time: 113.68 s
2024-04-21 19:24:19.783766: Yayy! New best EMA pseudo Dice: 0.7533
2024-04-21 19:24:23.276521: 
2024-04-21 19:24:23.276634: Epoch 49
2024-04-21 19:24:23.276715: Current learning rate: 0.00546
2024-04-21 19:26:15.381147: train_loss -0.5741
2024-04-21 19:26:15.381337: val_loss -0.5672
2024-04-21 19:26:15.381381: Pseudo dice [0.7612, 0.676]
2024-04-21 19:26:15.381430: Epoch time: 112.11 s
2024-04-21 19:26:18.734975: 
2024-04-21 19:26:18.735076: Epoch 50
2024-04-21 19:26:18.735160: Current learning rate: 0.00536
2024-04-21 19:28:10.749645: train_loss -0.5755
2024-04-21 19:28:10.749779: val_loss -0.561
2024-04-21 19:28:10.749821: Pseudo dice [0.7935, 0.7296]
2024-04-21 19:28:10.749866: Epoch time: 112.02 s
2024-04-21 19:28:11.775318: 
2024-04-21 19:28:11.775442: Epoch 51
2024-04-21 19:28:11.775525: Current learning rate: 0.00526
2024-04-21 19:30:04.936103: train_loss -0.5813
2024-04-21 19:30:04.936312: val_loss -0.5822
2024-04-21 19:30:04.936361: Pseudo dice [0.8229, 0.718]
2024-04-21 19:30:04.936409: Epoch time: 113.16 s
2024-04-21 19:30:05.777301: 
2024-04-21 19:30:05.777413: Epoch 52
2024-04-21 19:30:05.777493: Current learning rate: 0.00517
2024-04-21 19:31:59.084790: train_loss -0.5874
2024-04-21 19:31:59.084917: val_loss -0.613
2024-04-21 19:31:59.084960: Pseudo dice [0.7805, 0.7322]
2024-04-21 19:31:59.085005: Epoch time: 113.31 s
2024-04-21 19:31:59.928782: 
2024-04-21 19:31:59.928950: Epoch 53
2024-04-21 19:31:59.929033: Current learning rate: 0.00507
2024-04-21 19:33:53.402628: train_loss -0.6016
2024-04-21 19:33:53.402891: val_loss -0.6083
2024-04-21 19:33:53.402938: Pseudo dice [0.7982, 0.7203]
2024-04-21 19:33:53.402997: Epoch time: 113.47 s
2024-04-21 19:33:53.403033: Yayy! New best EMA pseudo Dice: 0.7539
2024-04-21 19:33:56.819283: 
2024-04-21 19:33:56.819449: Epoch 54
2024-04-21 19:33:56.819535: Current learning rate: 0.00497
2024-04-21 19:35:48.823076: train_loss -0.5928
2024-04-21 19:35:48.823293: val_loss -0.5725
2024-04-21 19:35:48.823341: Pseudo dice [0.797, 0.6685]
2024-04-21 19:35:48.823395: Epoch time: 112.0 s
2024-04-21 19:35:49.666303: 
2024-04-21 19:35:49.666407: Epoch 55
2024-04-21 19:35:49.666489: Current learning rate: 0.00487
2024-04-21 19:37:43.366453: train_loss -0.593
2024-04-21 19:37:43.366600: val_loss -0.5993
2024-04-21 19:37:43.366642: Pseudo dice [0.7968, 0.7264]
2024-04-21 19:37:43.366686: Epoch time: 113.7 s
2024-04-21 19:37:44.256903: 
2024-04-21 19:37:44.257011: Epoch 56
2024-04-21 19:37:44.257091: Current learning rate: 0.00478
2024-04-21 19:39:37.713190: train_loss -0.5809
2024-04-21 19:39:37.713356: val_loss -0.6078
2024-04-21 19:39:37.713399: Pseudo dice [0.8073, 0.7491]
2024-04-21 19:39:37.713446: Epoch time: 113.46 s
2024-04-21 19:39:37.713480: Yayy! New best EMA pseudo Dice: 0.7553
2024-04-21 19:39:42.243639: 
2024-04-21 19:39:42.243752: Epoch 57
2024-04-21 19:39:42.243830: Current learning rate: 0.00468
2024-04-21 19:41:34.209098: train_loss -0.5954
2024-04-21 19:41:34.209247: val_loss -0.6114
2024-04-21 19:41:34.209288: Pseudo dice [0.8437, 0.7061]
2024-04-21 19:41:34.209334: Epoch time: 111.97 s
2024-04-21 19:41:34.209367: Yayy! New best EMA pseudo Dice: 0.7573
2024-04-21 19:41:38.566731: 
2024-04-21 19:41:38.566844: Epoch 58
2024-04-21 19:41:38.566923: Current learning rate: 0.00458
2024-04-21 19:43:30.282491: train_loss -0.6043
2024-04-21 19:43:30.282653: val_loss -0.6003
2024-04-21 19:43:30.282699: Pseudo dice [0.792, 0.7275]
2024-04-21 19:43:30.282747: Epoch time: 111.72 s
2024-04-21 19:43:30.282780: Yayy! New best EMA pseudo Dice: 0.7575
2024-04-21 19:43:34.163334: 
2024-04-21 19:43:34.163449: Epoch 59
2024-04-21 19:43:34.163533: Current learning rate: 0.00448
2024-04-21 19:45:26.101347: train_loss -0.6007
2024-04-21 19:45:26.101619: val_loss -0.6237
2024-04-21 19:45:26.101667: Pseudo dice [0.8373, 0.7109]
2024-04-21 19:45:26.101719: Epoch time: 111.94 s
2024-04-21 19:45:26.101755: Yayy! New best EMA pseudo Dice: 0.7592
2024-04-21 19:45:29.766855: 
2024-04-21 19:45:29.766954: Epoch 60
2024-04-21 19:45:29.767035: Current learning rate: 0.00438
2024-04-21 19:47:21.946634: train_loss -0.6025
2024-04-21 19:47:21.946784: val_loss -0.6164
2024-04-21 19:47:21.946826: Pseudo dice [0.8298, 0.7206]
2024-04-21 19:47:21.946873: Epoch time: 112.18 s
2024-04-21 19:47:21.946906: Yayy! New best EMA pseudo Dice: 0.7608
2024-04-21 19:47:26.161922: 
2024-04-21 19:47:26.162033: Epoch 61
2024-04-21 19:47:26.162119: Current learning rate: 0.00429
2024-04-21 19:49:17.725110: train_loss -0.6151
2024-04-21 19:49:17.725312: val_loss -0.5849
2024-04-21 19:49:17.725356: Pseudo dice [0.7723, 0.7335]
2024-04-21 19:49:17.725405: Epoch time: 111.56 s
2024-04-21 19:49:18.585583: 
2024-04-21 19:49:18.585731: Epoch 62
2024-04-21 19:49:18.585812: Current learning rate: 0.00419
2024-04-21 19:51:12.092863: train_loss -0.5919
2024-04-21 19:51:12.093128: val_loss -0.5884
2024-04-21 19:51:12.093175: Pseudo dice [0.7936, 0.721]
2024-04-21 19:51:12.093233: Epoch time: 113.51 s
2024-04-21 19:51:13.142320: 
2024-04-21 19:51:13.142440: Epoch 63
2024-04-21 19:51:13.142521: Current learning rate: 0.00409
2024-04-21 19:53:06.683003: train_loss -0.6251
2024-04-21 19:53:06.683185: val_loss -0.615
2024-04-21 19:53:06.683233: Pseudo dice [0.8004, 0.764]
2024-04-21 19:53:06.683282: Epoch time: 113.54 s
2024-04-21 19:53:06.683315: Yayy! New best EMA pseudo Dice: 0.762
2024-04-21 19:53:09.779937: 
2024-04-21 19:53:09.780075: Epoch 64
2024-04-21 19:53:09.780155: Current learning rate: 0.00399
2024-04-21 19:55:01.785707: train_loss -0.5941
2024-04-21 19:55:01.785862: val_loss -0.5487
2024-04-21 19:55:01.785905: Pseudo dice [0.7618, 0.7323]
2024-04-21 19:55:01.785953: Epoch time: 112.01 s
2024-04-21 19:55:02.643166: 
2024-04-21 19:55:02.643265: Epoch 65
2024-04-21 19:55:02.643351: Current learning rate: 0.00389
2024-04-21 19:56:55.708309: train_loss -0.6037
2024-04-21 19:56:55.708462: val_loss -0.6014
2024-04-21 19:56:55.708506: Pseudo dice [0.8094, 0.7137]
2024-04-21 19:56:55.708619: Epoch time: 113.07 s
2024-04-21 19:56:56.573676: 
2024-04-21 19:56:56.573928: Epoch 66
2024-04-21 19:56:56.574016: Current learning rate: 0.00379
2024-04-21 19:58:49.657152: train_loss -0.6098
2024-04-21 19:58:49.657291: val_loss -0.6068
2024-04-21 19:58:49.657337: Pseudo dice [0.8248, 0.7397]
2024-04-21 19:58:49.657385: Epoch time: 113.08 s
2024-04-21 19:58:49.657418: Yayy! New best EMA pseudo Dice: 0.7627
2024-04-21 19:58:54.022171: 
2024-04-21 19:58:54.022281: Epoch 67
2024-04-21 19:58:54.022371: Current learning rate: 0.00369
2024-04-21 20:00:45.526132: train_loss -0.6148
2024-04-21 20:00:45.526318: val_loss -0.622
2024-04-21 20:00:45.526371: Pseudo dice [0.8095, 0.7444]
2024-04-21 20:00:45.526418: Epoch time: 111.5 s
2024-04-21 20:00:45.526451: Yayy! New best EMA pseudo Dice: 0.7642
2024-04-21 20:00:50.128418: 
2024-04-21 20:00:50.128529: Epoch 68
2024-04-21 20:00:50.128615: Current learning rate: 0.00359
2024-04-21 20:02:41.607021: train_loss -0.6167
2024-04-21 20:02:41.607173: val_loss -0.5976
2024-04-21 20:02:41.607217: Pseudo dice [0.7642, 0.7195]
2024-04-21 20:02:41.607264: Epoch time: 111.48 s
2024-04-21 20:02:42.669073: 
2024-04-21 20:02:42.669178: Epoch 69
2024-04-21 20:02:42.669258: Current learning rate: 0.00349
2024-04-21 20:04:35.868662: train_loss -0.6096
2024-04-21 20:04:35.868824: val_loss -0.5773
2024-04-21 20:04:35.868866: Pseudo dice [0.7973, 0.7389]
2024-04-21 20:04:35.868912: Epoch time: 113.2 s
2024-04-21 20:04:36.741465: 
2024-04-21 20:04:36.741575: Epoch 70
2024-04-21 20:04:36.741653: Current learning rate: 0.00338
2024-04-21 20:06:30.091049: train_loss -0.6012
2024-04-21 20:06:30.091187: val_loss -0.6148
2024-04-21 20:06:30.091230: Pseudo dice [0.7859, 0.7454]
2024-04-21 20:06:30.091278: Epoch time: 113.35 s
2024-04-21 20:06:30.972538: 
2024-04-21 20:06:30.972658: Epoch 71
2024-04-21 20:06:30.972742: Current learning rate: 0.00328
2024-04-21 20:08:24.235880: train_loss -0.6073
2024-04-21 20:08:24.236037: val_loss -0.6094
2024-04-21 20:08:24.236079: Pseudo dice [0.8244, 0.7487]
2024-04-21 20:08:24.236124: Epoch time: 113.26 s
2024-04-21 20:08:24.236158: Yayy! New best EMA pseudo Dice: 0.7652
2024-04-21 20:08:27.913358: 
2024-04-21 20:08:27.913468: Epoch 72
2024-04-21 20:08:27.913556: Current learning rate: 0.00318
2024-04-21 20:10:20.116795: train_loss -0.6216
2024-04-21 20:10:20.116974: val_loss -0.5961
2024-04-21 20:10:20.117017: Pseudo dice [0.7912, 0.7504]
2024-04-21 20:10:20.117067: Epoch time: 112.2 s
2024-04-21 20:10:20.117102: Yayy! New best EMA pseudo Dice: 0.7658
2024-04-21 20:10:23.041564: 
2024-04-21 20:10:23.041679: Epoch 73
2024-04-21 20:10:23.041762: Current learning rate: 0.00308
2024-04-21 20:12:15.491703: train_loss -0.6184
2024-04-21 20:12:15.491863: val_loss -0.5975
2024-04-21 20:12:15.491907: Pseudo dice [0.8226, 0.7111]
2024-04-21 20:12:15.491954: Epoch time: 112.45 s
2024-04-21 20:12:15.491987: Yayy! New best EMA pseudo Dice: 0.7659
2024-04-21 20:12:20.291330: 
2024-04-21 20:12:20.291441: Epoch 74
2024-04-21 20:12:20.291523: Current learning rate: 0.00297
2024-04-21 20:14:11.963041: train_loss -0.6257
2024-04-21 20:14:11.963185: val_loss -0.615
2024-04-21 20:14:11.963228: Pseudo dice [0.7774, 0.7722]
2024-04-21 20:14:11.963274: Epoch time: 111.67 s
2024-04-21 20:14:11.963306: Yayy! New best EMA pseudo Dice: 0.7668
2024-04-21 20:14:16.300759: 
2024-04-21 20:14:16.300927: Epoch 75
2024-04-21 20:14:16.301014: Current learning rate: 0.00287
2024-04-21 20:16:08.074727: train_loss -0.6142
2024-04-21 20:16:08.074887: val_loss -0.5922
2024-04-21 20:16:08.074930: Pseudo dice [0.751, 0.7591]
2024-04-21 20:16:08.074978: Epoch time: 111.77 s
2024-04-21 20:16:08.959538: 
2024-04-21 20:16:08.959652: Epoch 76
2024-04-21 20:16:08.959738: Current learning rate: 0.00277
2024-04-21 20:18:02.026076: train_loss -0.6141
2024-04-21 20:18:02.026255: val_loss -0.6114
2024-04-21 20:18:02.026299: Pseudo dice [0.8201, 0.7341]
2024-04-21 20:18:02.026358: Epoch time: 113.07 s
2024-04-21 20:18:02.944411: 
2024-04-21 20:18:02.944532: Epoch 77
2024-04-21 20:18:02.944616: Current learning rate: 0.00266
2024-04-21 20:19:55.904986: train_loss -0.6116
2024-04-21 20:19:55.905152: val_loss -0.5956
2024-04-21 20:19:55.905194: Pseudo dice [0.7947, 0.758]
2024-04-21 20:19:55.905241: Epoch time: 112.96 s
2024-04-21 20:19:55.905277: Yayy! New best EMA pseudo Dice: 0.7677
2024-04-21 20:19:59.955113: 
2024-04-21 20:19:59.955231: Epoch 78
2024-04-21 20:19:59.955312: Current learning rate: 0.00256
2024-04-21 20:21:51.758991: train_loss -0.6286
2024-04-21 20:21:51.759132: val_loss -0.6027
2024-04-21 20:21:51.759174: Pseudo dice [0.8007, 0.7353]
2024-04-21 20:21:51.759221: Epoch time: 111.8 s
2024-04-21 20:21:51.759256: Yayy! New best EMA pseudo Dice: 0.7677
2024-04-21 20:21:56.259001: 
2024-04-21 20:21:56.259090: Epoch 79
2024-04-21 20:21:56.259169: Current learning rate: 0.00245
2024-04-21 20:23:47.808370: train_loss -0.6274
2024-04-21 20:23:47.808542: val_loss -0.5679
2024-04-21 20:23:47.808586: Pseudo dice [0.781, 0.7232]
2024-04-21 20:23:47.808632: Epoch time: 111.55 s
2024-04-21 20:23:48.917056: 
2024-04-21 20:23:48.917180: Epoch 80
2024-04-21 20:23:48.917268: Current learning rate: 0.00235
2024-04-21 20:25:42.392388: train_loss -0.6342
2024-04-21 20:25:42.392593: val_loss -0.6224
2024-04-21 20:25:42.392638: Pseudo dice [0.8087, 0.7514]
2024-04-21 20:25:42.392688: Epoch time: 113.48 s
2024-04-21 20:25:43.292245: 
2024-04-21 20:25:43.292349: Epoch 81
2024-04-21 20:25:43.292428: Current learning rate: 0.00224
2024-04-21 20:27:37.010448: train_loss -0.6054
2024-04-21 20:27:37.010638: val_loss -0.5951
2024-04-21 20:27:37.010682: Pseudo dice [0.7862, 0.7456]
2024-04-21 20:27:37.010731: Epoch time: 113.72 s
2024-04-21 20:27:37.924058: 
2024-04-21 20:27:37.924192: Epoch 82
2024-04-21 20:27:37.924262: Current learning rate: 0.00214
2024-04-21 20:29:31.521618: train_loss -0.6338
2024-04-21 20:29:31.521806: val_loss -0.6422
2024-04-21 20:29:31.521849: Pseudo dice [0.8398, 0.7638]
2024-04-21 20:29:31.521896: Epoch time: 113.6 s
2024-04-21 20:29:31.521930: Yayy! New best EMA pseudo Dice: 0.7708
2024-04-21 20:29:36.212579: 
2024-04-21 20:29:36.212685: Epoch 83
2024-04-21 20:29:36.212762: Current learning rate: 0.00203
2024-04-21 20:31:27.763218: train_loss -0.6256
2024-04-21 20:31:27.763346: val_loss -0.5994
2024-04-21 20:31:27.763389: Pseudo dice [0.8399, 0.7284]
2024-04-21 20:31:27.763435: Epoch time: 111.55 s
2024-04-21 20:31:27.763469: Yayy! New best EMA pseudo Dice: 0.7722
2024-04-21 20:31:31.662424: 
2024-04-21 20:31:31.662526: Epoch 84
2024-04-21 20:31:31.662603: Current learning rate: 0.00192
2024-04-21 20:33:23.607933: train_loss -0.6051
2024-04-21 20:33:23.608063: val_loss -0.6629
2024-04-21 20:33:23.608108: Pseudo dice [0.8544, 0.7547]
2024-04-21 20:33:23.608154: Epoch time: 111.95 s
2024-04-21 20:33:23.608188: Yayy! New best EMA pseudo Dice: 0.7754
2024-04-21 20:33:27.875875: 
2024-04-21 20:33:27.875968: Epoch 85
2024-04-21 20:33:27.876048: Current learning rate: 0.00181
2024-04-21 20:35:19.277873: train_loss -0.6256
2024-04-21 20:35:19.278027: val_loss -0.592
2024-04-21 20:35:19.278074: Pseudo dice [0.7884, 0.7357]
2024-04-21 20:35:19.278123: Epoch time: 111.4 s
2024-04-21 20:35:20.335336: 
2024-04-21 20:35:20.335501: Epoch 86
2024-04-21 20:35:20.335588: Current learning rate: 0.0017
2024-04-21 20:37:13.481107: train_loss -0.6103
2024-04-21 20:37:13.481296: val_loss -0.6113
2024-04-21 20:37:13.481343: Pseudo dice [0.8224, 0.7058]
2024-04-21 20:37:13.481395: Epoch time: 113.15 s
2024-04-21 20:37:14.314351: 
2024-04-21 20:37:14.314450: Epoch 87
2024-04-21 20:37:14.314529: Current learning rate: 0.00159
2024-04-21 20:39:07.719415: train_loss -0.6292
2024-04-21 20:39:07.719631: val_loss -0.6031
2024-04-21 20:39:07.719716: Pseudo dice [0.8192, 0.7383]
2024-04-21 20:39:07.719819: Epoch time: 113.41 s
2024-04-21 20:39:08.550452: 
2024-04-21 20:39:08.550564: Epoch 88
2024-04-21 20:39:08.550653: Current learning rate: 0.00148
2024-04-21 20:41:02.106938: train_loss -0.628
2024-04-21 20:41:02.107129: val_loss -0.6073
2024-04-21 20:41:02.107175: Pseudo dice [0.8123, 0.7153]
2024-04-21 20:41:02.107300: Epoch time: 113.56 s
2024-04-21 20:41:02.938862: 
2024-04-21 20:41:02.939019: Epoch 89
2024-04-21 20:41:02.939107: Current learning rate: 0.00137
2024-04-21 20:42:56.336553: train_loss -0.6409
2024-04-21 20:42:56.336763: val_loss -0.623
2024-04-21 20:42:56.336808: Pseudo dice [0.805, 0.7409]
2024-04-21 20:42:56.336855: Epoch time: 113.4 s
2024-04-21 20:42:57.165077: 
2024-04-21 20:42:57.165176: Epoch 90
2024-04-21 20:42:57.165255: Current learning rate: 0.00126
2024-04-21 20:44:50.526627: train_loss -0.6255
2024-04-21 20:44:50.526752: val_loss -0.6471
2024-04-21 20:44:50.526793: Pseudo dice [0.8317, 0.7506]
2024-04-21 20:44:50.526839: Epoch time: 113.36 s
2024-04-21 20:44:51.355830: 
2024-04-21 20:44:51.355922: Epoch 91
2024-04-21 20:44:51.356002: Current learning rate: 0.00115
2024-04-21 20:46:44.641576: train_loss -0.6301
2024-04-21 20:46:44.641713: val_loss -0.6515
2024-04-21 20:46:44.641757: Pseudo dice [0.8096, 0.7602]
2024-04-21 20:46:44.641802: Epoch time: 113.29 s
2024-04-21 20:46:44.641835: Yayy! New best EMA pseudo Dice: 0.7756
2024-04-21 20:46:48.954345: 
2024-04-21 20:46:48.954455: Epoch 92
2024-04-21 20:46:48.954536: Current learning rate: 0.00103
2024-04-21 20:48:40.333465: train_loss -0.631
2024-04-21 20:48:40.333616: val_loss -0.6005
2024-04-21 20:48:40.333657: Pseudo dice [0.8007, 0.7289]
2024-04-21 20:48:40.333702: Epoch time: 111.38 s
2024-04-21 20:48:41.161048: 
2024-04-21 20:48:41.161164: Epoch 93
2024-04-21 20:48:41.161245: Current learning rate: 0.00091
2024-04-21 20:50:34.387795: train_loss -0.6259
2024-04-21 20:50:34.388014: val_loss -0.5979
2024-04-21 20:50:34.388058: Pseudo dice [0.8165, 0.7349]
2024-04-21 20:50:34.388109: Epoch time: 113.23 s
2024-04-21 20:50:35.220427: 
2024-04-21 20:50:35.220555: Epoch 94
2024-04-21 20:50:35.220633: Current learning rate: 0.00079
2024-04-21 20:52:28.507586: train_loss -0.6353
2024-04-21 20:52:28.507757: val_loss -0.6049
2024-04-21 20:52:28.507801: Pseudo dice [0.815, 0.7622]
2024-04-21 20:52:28.507848: Epoch time: 113.29 s
2024-04-21 20:52:28.507882: Yayy! New best EMA pseudo Dice: 0.776
2024-04-21 20:52:32.903106: 
2024-04-21 20:52:32.903215: Epoch 95
2024-04-21 20:52:32.903294: Current learning rate: 0.00067
2024-04-21 20:54:24.419472: train_loss -0.6232
2024-04-21 20:54:24.419630: val_loss -0.6235
2024-04-21 20:54:24.419674: Pseudo dice [0.8285, 0.7428]
2024-04-21 20:54:24.419721: Epoch time: 111.52 s
2024-04-21 20:54:24.419755: Yayy! New best EMA pseudo Dice: 0.777
2024-04-21 20:54:27.642796: 
2024-04-21 20:54:27.642969: Epoch 96
2024-04-21 20:54:27.643054: Current learning rate: 0.00055
2024-04-21 20:56:19.974663: train_loss -0.6365
2024-04-21 20:56:19.974827: val_loss -0.6522
2024-04-21 20:56:19.974870: Pseudo dice [0.8116, 0.7681]
2024-04-21 20:56:19.974918: Epoch time: 112.33 s
2024-04-21 20:56:19.974951: Yayy! New best EMA pseudo Dice: 0.7783
2024-04-21 20:56:25.012891: 
2024-04-21 20:56:25.013074: Epoch 97
2024-04-21 20:56:25.013165: Current learning rate: 0.00043
2024-04-21 20:58:16.335141: train_loss -0.6421
2024-04-21 20:58:16.335274: val_loss -0.6255
2024-04-21 20:58:16.335317: Pseudo dice [0.8096, 0.7616]
2024-04-21 20:58:16.335365: Epoch time: 111.32 s
2024-04-21 20:58:16.335401: Yayy! New best EMA pseudo Dice: 0.779
2024-04-21 20:58:20.785129: 
2024-04-21 20:58:20.785252: Epoch 98
2024-04-21 20:58:20.785332: Current learning rate: 0.0003
2024-04-21 21:00:12.482193: train_loss -0.6239
2024-04-21 21:00:12.482322: val_loss -0.6243
2024-04-21 21:00:12.482458: Pseudo dice [0.8171, 0.7612]
2024-04-21 21:00:12.482506: Epoch time: 111.7 s
2024-04-21 21:00:12.482541: Yayy! New best EMA pseudo Dice: 0.78
2024-04-21 21:00:16.732867: 
2024-04-21 21:00:16.732962: Epoch 99
2024-04-21 21:00:16.733040: Current learning rate: 0.00016
2024-04-21 21:02:08.030991: train_loss -0.6314
2024-04-21 21:02:08.031165: val_loss -0.624
2024-04-21 21:02:08.031209: Pseudo dice [0.8272, 0.7475]
2024-04-21 21:02:08.031258: Epoch time: 111.3 s
2024-04-21 21:02:08.031293: Yayy! New best EMA pseudo Dice: 0.7807
2024-04-21 21:02:13.028623: Training done.
2024-04-21 21:02:13.038166: Using splits from existing split file: /media/HDD_4TB_2/sergio/TFM/hecktor/hecktor/data/nnUNet_preprocessed/Dataset500_HeadNeckPTCT/splits_final.json
2024-04-21 21:02:13.038597: The split file contains 5 splits.
2024-04-21 21:02:13.038625: Desired fold for training: 3
2024-04-21 21:02:13.038646: This split has 377 training and 94 validation cases.
2024-04-21 21:02:13.039116: predicting CHUM_002
2024-04-21 21:02:13.039809: CHUM_002, shape torch.Size([2, 174, 176, 176]), rank 0
2024-04-21 21:02:18.112211: predicting CHUM_006
2024-04-21 21:02:18.114909: CHUM_006, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:02:22.031224: predicting CHUM_012
2024-04-21 21:02:22.033683: CHUM_012, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:02:26.096333: predicting CHUM_034
2024-04-21 21:02:26.099300: CHUM_034, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:02:30.223303: predicting CHUM_035
2024-04-21 21:02:30.225868: CHUM_035, shape torch.Size([2, 175, 176, 176]), rank 0
2024-04-21 21:02:34.402461: predicting CHUM_043
2024-04-21 21:02:34.404786: CHUM_043, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:02:38.617273: predicting CHUM_048
2024-04-21 21:02:38.619905: CHUM_048, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:02:42.833554: predicting CHUP_012
2024-04-21 21:02:42.836228: CHUP_012, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:02:47.026683: predicting CHUP_017
2024-04-21 21:02:47.029049: CHUP_017, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:02:51.245108: predicting CHUP_022
2024-04-21 21:02:51.247763: CHUP_022, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:02:55.456240: predicting CHUP_033
2024-04-21 21:02:55.458646: CHUP_033, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:02:59.668987: predicting CHUP_034
2024-04-21 21:02:59.671526: CHUP_034, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:03.883201: predicting CHUP_041
2024-04-21 21:03:03.885764: CHUP_041, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:08.127080: predicting CHUP_048
2024-04-21 21:03:08.129265: CHUP_048, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:12.342245: predicting CHUP_049
2024-04-21 21:03:12.344574: CHUP_049, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:16.564841: predicting CHUP_050
2024-04-21 21:03:16.567567: CHUP_050, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:20.791728: predicting CHUP_052
2024-04-21 21:03:20.794301: CHUP_052, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:25.026358: predicting CHUP_055
2024-04-21 21:03:25.028682: CHUP_055, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:29.262867: predicting CHUP_060
2024-04-21 21:03:29.265279: CHUP_060, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:33.495790: predicting CHUP_068
2024-04-21 21:03:33.498158: CHUP_068, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:37.733977: predicting CHUP_071
2024-04-21 21:03:37.736609: CHUP_071, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:41.947630: predicting CHUS_005
2024-04-21 21:03:41.950045: CHUS_005, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:46.193148: predicting CHUS_010
2024-04-21 21:03:46.196065: CHUS_010, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:50.435177: predicting CHUS_019
2024-04-21 21:03:50.437715: CHUS_019, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:54.685458: predicting CHUS_020
2024-04-21 21:03:54.688343: CHUS_020, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:03:58.920798: predicting CHUS_031
2024-04-21 21:03:58.923167: CHUS_031, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:03.163455: predicting CHUS_045
2024-04-21 21:04:03.166260: CHUS_045, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:07.411235: predicting CHUS_058
2024-04-21 21:04:07.413738: CHUS_058, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:11.647883: predicting CHUS_061
2024-04-21 21:04:11.650559: CHUS_061, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:15.884351: predicting CHUS_085
2024-04-21 21:04:15.886773: CHUS_085, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:20.129019: predicting CHUS_097
2024-04-21 21:04:20.131331: CHUS_097, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:24.375129: predicting CHUV_002
2024-04-21 21:04:24.377840: CHUV_002, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:28.619094: predicting CHUV_015
2024-04-21 21:04:28.621461: CHUV_015, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:32.851353: predicting CHUV_016
2024-04-21 21:04:32.853952: CHUV_016, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:37.090639: predicting CHUV_017
2024-04-21 21:04:37.093641: CHUV_017, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:41.316222: predicting CHUV_021
2024-04-21 21:04:41.319091: CHUV_021, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:45.567972: predicting CHUV_022
2024-04-21 21:04:45.570916: CHUV_022, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:49.840109: predicting CHUV_023
2024-04-21 21:04:49.842516: CHUV_023, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:54.072118: predicting CHUV_028
2024-04-21 21:04:54.074517: CHUV_028, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:04:58.309061: predicting CHUV_034
2024-04-21 21:04:58.311816: CHUV_034, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:02.550779: predicting CHUV_035
2024-04-21 21:05:02.553462: CHUV_035, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:06.804315: predicting CHUV_037
2024-04-21 21:05:06.807153: CHUV_037, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:11.071445: predicting CHUV_047
2024-04-21 21:05:11.073879: CHUV_047, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:15.332844: predicting CHUV_048
2024-04-21 21:05:15.335547: CHUV_048, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:19.571688: predicting CHUV_051
2024-04-21 21:05:19.574221: CHUV_051, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:23.822010: predicting HGJ_010
2024-04-21 21:05:23.824504: HGJ_010, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:28.055764: predicting HGJ_013
2024-04-21 21:05:28.058707: HGJ_013, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:32.302663: predicting HGJ_017
2024-04-21 21:05:32.305138: HGJ_017, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:36.542280: predicting HGJ_025
2024-04-21 21:05:36.544950: HGJ_025, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:40.780247: predicting HGJ_030
2024-04-21 21:05:40.782814: HGJ_030, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:45.026664: predicting HGJ_036
2024-04-21 21:05:45.029162: HGJ_036, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:49.286840: predicting HGJ_066
2024-04-21 21:05:49.289834: HGJ_066, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:53.537924: predicting HGJ_067
2024-04-21 21:05:53.539981: HGJ_067, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:05:57.779727: predicting HGJ_073
2024-04-21 21:05:57.782654: HGJ_073, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:06:02.042575: predicting HGJ_080
2024-04-21 21:06:02.045517: HGJ_080, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:06:06.296487: predicting HGJ_081
2024-04-21 21:06:06.298988: HGJ_081, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:06:10.551425: predicting HGJ_091
2024-04-21 21:06:10.554085: HGJ_091, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:06:14.782683: predicting HMR_004
2024-04-21 21:06:14.785605: HMR_004, shape torch.Size([2, 171, 176, 176]), rank 0
2024-04-21 21:06:19.035313: predicting HMR_014
2024-04-21 21:06:19.038020: HMR_014, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:06:23.279842: predicting HMR_030
2024-04-21 21:06:23.282359: HMR_030, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:06:27.518770: predicting MDA_005
2024-04-21 21:06:27.521206: MDA_005, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:06:31.749799: predicting MDA_007
2024-04-21 21:06:31.751785: MDA_007, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:06:35.998774: predicting MDA_015
2024-04-21 21:06:36.001039: MDA_015, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:06:40.242701: predicting MDA_026
2024-04-21 21:06:40.245218: MDA_026, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:06:44.499448: predicting MDA_028
2024-04-21 21:06:44.502116: MDA_028, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:06:48.759126: predicting MDA_032
2024-04-21 21:06:48.761222: MDA_032, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:06:53.003056: predicting MDA_036
2024-04-21 21:06:53.005478: MDA_036, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:06:57.282513: predicting MDA_039
2024-04-21 21:06:57.285002: MDA_039, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:01.535990: predicting MDA_045
2024-04-21 21:07:01.538530: MDA_045, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:05.772295: predicting MDA_048
2024-04-21 21:07:05.775453: MDA_048, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:10.017287: predicting MDA_066
2024-04-21 21:07:10.019822: MDA_066, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:14.271577: predicting MDA_070
2024-04-21 21:07:14.274193: MDA_070, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:18.518752: predicting MDA_073
2024-04-21 21:07:18.521120: MDA_073, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:22.763645: predicting MDA_076
2024-04-21 21:07:22.765825: MDA_076, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:27.017295: predicting MDA_077
2024-04-21 21:07:27.019852: MDA_077, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:31.268224: predicting MDA_080
2024-04-21 21:07:31.270877: MDA_080, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:35.504104: predicting MDA_091
2024-04-21 21:07:35.506875: MDA_091, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:39.745597: predicting MDA_095
2024-04-21 21:07:39.748079: MDA_095, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:43.997286: predicting MDA_098
2024-04-21 21:07:43.999877: MDA_098, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:48.227655: predicting MDA_105
2024-04-21 21:07:48.229703: MDA_105, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:52.489602: predicting MDA_114
2024-04-21 21:07:52.492001: MDA_114, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:07:56.726500: predicting MDA_116
2024-04-21 21:07:56.729100: MDA_116, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:08:00.960942: predicting MDA_123
2024-04-21 21:08:00.963219: MDA_123, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:08:05.187595: predicting MDA_129
2024-04-21 21:08:05.189973: MDA_129, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:08:09.406768: predicting MDA_132
2024-04-21 21:08:09.409242: MDA_132, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:08:13.630499: predicting MDA_133
2024-04-21 21:08:13.632920: MDA_133, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:08:17.867595: predicting MDA_134
2024-04-21 21:08:17.869838: MDA_134, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:08:22.115380: predicting MDA_135
2024-04-21 21:08:22.117280: MDA_135, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:08:26.355069: predicting MDA_140
2024-04-21 21:08:26.357313: MDA_140, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:08:30.594675: predicting MDA_150
2024-04-21 21:08:30.597367: MDA_150, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:08:34.833638: predicting MDA_169
2024-04-21 21:08:34.835712: MDA_169, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:08:39.075619: predicting MDA_173
2024-04-21 21:08:39.077882: MDA_173, shape torch.Size([2, 174, 176, 176]), rank 0
2024-04-21 21:08:43.310640: predicting MDA_191
2024-04-21 21:08:43.313265: MDA_191, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:08:47.549241: predicting MDA_198
2024-04-21 21:08:47.551799: MDA_198, shape torch.Size([2, 176, 176, 176]), rank 0
2024-04-21 21:08:57.852729: Validation complete
2024-04-21 21:08:57.852794: Mean Validation Dice:  0.6549831442083935
